{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKzF6dMaiLyP"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/master/assignments/assignment_yourname_class7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDTXd8-Lmp8Q"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
    "\n",
    "**Module 5 Assignment: Computer Vision Neural Network**\n",
    "\n",
    "**Student Name: Your Name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncNrAEpzmp8S"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "This assignment will be most straightforward if you use Google CoLab, because it requires both PyTorch and YOLOv5 to be installed. It will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fU9UhAxTmp8S",
    "outputId": "3c9be34f-d8f7-48e7-da07-8fcb4e8064e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Note: using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSKZqD1Mmp-C"
   },
   "source": [
    "# Assignment Submit Function\n",
    "\n",
    "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems.\n",
    "\n",
    "**It is unlikely that should need to modify this function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7F2MhA7bjag8"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - List of pandas dataframes or images.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    payload = []\n",
    "    for item in data:\n",
    "        if type(item) is PIL.Image.Image:\n",
    "            buffered = BytesIO()\n",
    "            item.save(buffered, format=\"PNG\")\n",
    "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
    "        elif type(item) is pd.core.frame.DataFrame:\n",
    "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
    "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code==200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fJKkSenqklH"
   },
   "source": [
    "# Assignment Instructions\n",
    "\n",
    "For this assignment, you will use YOLO running on Google CoLab.  I suggest that you run this assignment on CoLab because the example code below is already setup to get you started with the correct versions of  YOLO on PyTorch.\n",
    "\n",
    "For this assignment you are provided with 10 image files that contain 10 different webcam pictures taken at the [Venice Sidewalk Cafe](https://www.westland.net/beachcam/) a WebCam that has been in opration since 1996.  You can find the 10 images here:\n",
    "\n",
    "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg\n",
    "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.jpg\n",
    "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.jpg\n",
    "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.jpg\n",
    "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.jpg\n",
    "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.jpg\n",
    "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.jpg\n",
    "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.jpg\n",
    "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.jpg\n",
    "* https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.jpg\n",
    "\n",
    "You can see a sample of the WebCam here:\n",
    "\n",
    "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg)\n",
    "\n",
    "YOLO does quite well-recognizing objects in this webcam, as the following image illustrates.\n",
    "\n",
    "![alt text](https://data.heatonresearch.com/data/t81-558/sidewalk/predictions.jpg)\n",
    "\n",
    "You are to write a script that counts the number of certain objects in each of the images.  Specifically, you are looking for:\n",
    "\n",
    "* person\n",
    "* car\n",
    "* bicycle\n",
    "* motorbike\n",
    "* umbrella\n",
    "* handbag\n",
    "\n",
    "\n",
    "Your submitted data frame should also contain a column that identifies which image generated each row.  This column should be named **image** and contain integer numbers between 1 and 10.  There should be 10 rows in total.  The complete data frame should look something like this (not necessarily exactly these numbers).\n",
    "\n",
    "|image|person|car|bicycle|motorbike|umbrella|handbag|\n",
    "|-|-|-|-|-|-|-|\n",
    "|1|23|0|3|4|0|0|\n",
    "|2|27|1|8|2|0|0|\n",
    "|3|29|0|0|0|3|0|\n",
    "|...|...|...|...|...|...|...|\n",
    "\n",
    "\n",
    "The following code sets up YOLO and then dumps the classification information for the first image.  This notebook only serves to get you started.  Read in all ten images and generate a data frame that looks like the following. Use the **submit** function as you did in previous assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ym5_juokofQl"
   },
   "source": [
    "### Installing YOLOv5\n",
    "\n",
    "YOLO is not available directly through either PIP or CONDA.  Additionally, YOLO is not installed in Google CoLab by default. Therefore, whether you wish to use YOLO through CoLab or run it locally, you need to go through several steps to install it.  This section describes the process of installing YOLO.  The same steps apply to either CoLab or a local install.  For CoLab, you must repeat these steps each time the system restarts your virtual environment.  You must perform these steps only once for your virtual Python environment for a local install.  If you are installing locally, make sure to install to the same virtual environment you created for this course.  The following commands install YOLO directly from its GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VuTjby5MzEre",
    "outputId": "269620a5-92ed-4dab-f27b-956965a0d0a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.4/201.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!git clone https://github.com/ultralytics/yolov5 --tag 6.2  # clone\n",
    "!mv /content/6.2 /content/yolov5\n",
    "%pip install -qr /content/yolov5/requirements.txt  # install\n",
    "sys.path.insert(0,'/content/yolov5')\n",
    "\n",
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYOvD3M7ofQl"
   },
   "source": [
    "### Running YOLOv5\n",
    "\n",
    "In addition to the command line execution we just saw, the YOLO library can easily integrate with Python applications.  The following code adds the downloaded YOLOv5 to Python's environment, allowing **yolov5** to be imported like a regular Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MY3gVyidmp-K",
    "outputId": "071d2ee2-cebe-4a06-d6d7-05b45361e6f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5n - yolov5x6, custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGbur-vdZWyz"
   },
   "source": [
    "I built the following function from the code presented in the course module. The function combines some of the code from the module to accept an image and return what YOLO recognizes. Make sure to use the same two thres_xxx values I provided below to match the results that I got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFmqHkLbYQVm",
    "outputId": "6523c9ae-399c-444f-8127-9e25b6e3a592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           xmin        ymin         xmax        ymax  confidence  class  \\\n",
      "0   1232.664185  655.564087  1280.457642  785.814697    0.701470      0   \n",
      "1    897.502441  542.024292   940.235229  641.454651    0.668886      0   \n",
      "2    985.573364  506.579315  1029.304932  598.225830    0.643762      0   \n",
      "3   1052.518799  578.318298  1094.240479  687.382690    0.522934      0   \n",
      "4   1457.463501  316.237640  1521.751221  354.111542    0.469375      2   \n",
      "5    964.298828  596.666626  1018.449402  715.114868    0.416467      0   \n",
      "6    634.272827  443.288177   689.804321  535.599243    0.386331      0   \n",
      "7    675.782654  624.517822   757.266479  733.891968    0.345984      0   \n",
      "8    150.537537  280.010315   217.492279  330.766876    0.295688      0   \n",
      "9   1421.322754  351.651489  1458.115479  384.356110    0.285915      2   \n",
      "10  1212.849731  361.386353  1283.806519  401.129150    0.259512     25   \n",
      "\n",
      "        name  \n",
      "0     person  \n",
      "1     person  \n",
      "2     person  \n",
      "3     person  \n",
      "4        car  \n",
      "5     person  \n",
      "6     person  \n",
      "7     person  \n",
      "8     person  \n",
      "9        car  \n",
      "10  umbrella  \n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Add your solution here, put your results into submit_df\n",
    "\n",
    "# This is your student key that I emailed to you at the beginnning of the semester.\n",
    "#key = \"5iuwhudihwiao6dsfw7dE2ml08iNfVOg6l0O3M06\"  # This is an example key and will not work.\n",
    "key = \"uTtH5yNbPs9tZhhhhdRWsBf9V99RU2iP5cL7F3zH\"\n",
    "\n",
    "# You must also identify your source file.  (modify for your local setup)\n",
    "file='/content/drive/MyDrive/Colab Notebooks/assignment_yourname_class5.ipynb'  # Google CoLab\n",
    "\n",
    "# Starter code\n",
    "i = 1\n",
    "url = f\"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk{i}.jpg\"\n",
    "response = requests.get(url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Inference\n",
    "results = yolo_model(img)\n",
    "\n",
    "# Results\n",
    "df = results.pandas().xyxy[0]\n",
    "\n",
    "print(df)\n",
    "\n",
    "submit(source_file=file,data=[df],key=key,no=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #5 MyCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15935,
     "status": "ok",
     "timestamp": 1709240902045,
     "user": {
      "displayName": "hanhans Han",
      "userId": "17100325406789429061"
     },
     "user_tz": 360
    },
    "id": "7yhV6HkNBK1a",
    "outputId": "9ccbc4db-4238-45cb-e90b-75d5e79732e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Note: using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24078,
     "status": "ok",
     "timestamp": 1708994997371,
     "user": {
      "displayName": "hanhans Han",
      "userId": "17100325406789429061"
     },
     "user_tz": 360
    },
    "id": "lcJMGxsHBMBk",
    "outputId": "29f48bed-ade7-462c-e630-310fb9adc082"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.12 torch-2.1.0+cu121 CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.4/107.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!git clone https://github.com/ultralytics/yolov5 --tag 6.2  # clone\n",
    "!mv /content/6.2 /content/yolov5\n",
    "%pip install -qr /content/yolov5/requirements.txt  # install\n",
    "sys.path.insert(0,'/content/yolov5')\n",
    "\n",
    "import torch\n",
    "import utils\n",
    "display = utils.notebook_init()  # checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1708996043628,
     "user": {
      "displayName": "hanhans Han",
      "userId": "17100325406789429061"
     },
     "user_tz": 360
    },
    "id": "a1unnLNCCzFi",
    "outputId": "77474052-31f1-46c7-c8e6-db4819c07692"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.12 torch-2.1.0+cu121 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1541,
     "status": "ok",
     "timestamp": 1708996970682,
     "user": {
      "displayName": "hanhans Han",
      "userId": "17100325406789429061"
     },
     "user_tz": 360
    },
    "id": "z6ZsNupqIQpj",
    "outputId": "f691856d-316c-4109-a33d-442f561e038d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-27 01:22:49--  https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg\n",
      "Resolving data.heatonresearch.com (data.heatonresearch.com)... 52.84.125.38, 52.84.125.18, 52.84.125.73, ...\n",
      "Connecting to data.heatonresearch.com (data.heatonresearch.com)|52.84.125.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 71055 (69K) [image/jpeg]\n",
      "Saving to: ‘/content/images/sidewalk1.jpg’\n",
      "\n",
      "\r",
      "          /content/   0%[                    ]       0  --.-KB/s               \r",
      "/content/images/sid 100%[===================>]  69.39K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-02-27 01:22:49 (5.25 MB/s) - ‘/content/images/sidewalk1.jpg’ saved [71055/71055]\n",
      "\n",
      "--2024-02-27 01:22:49--  https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.jpg\n",
      "Resolving data.heatonresearch.com (data.heatonresearch.com)... 52.84.125.38, 52.84.125.18, 52.84.125.73, ...\n",
      "Connecting to data.heatonresearch.com (data.heatonresearch.com)|52.84.125.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 73422 (72K) [image/jpeg]\n",
      "Saving to: ‘/content/images/sidewalk2.jpg’\n",
      "\n",
      "/content/images/sid 100%[===================>]  71.70K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-02-27 01:22:49 (4.46 MB/s) - ‘/content/images/sidewalk2.jpg’ saved [73422/73422]\n",
      "\n",
      "--2024-02-27 01:22:49--  https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.jpg\n",
      "Resolving data.heatonresearch.com (data.heatonresearch.com)... 52.84.125.38, 52.84.125.18, 52.84.125.73, ...\n",
      "Connecting to data.heatonresearch.com (data.heatonresearch.com)|52.84.125.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 126939 (124K) [image/jpeg]\n",
      "Saving to: ‘/content/images/sidewalk3.jpg’\n",
      "\n",
      "/content/images/sid 100%[===================>] 123.96K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2024-02-27 01:22:49 (4.18 MB/s) - ‘/content/images/sidewalk3.jpg’ saved [126939/126939]\n",
      "\n",
      "--2024-02-27 01:22:49--  https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.jpg\n",
      "Resolving data.heatonresearch.com (data.heatonresearch.com)... 52.84.125.38, 52.84.125.18, 52.84.125.73, ...\n",
      "Connecting to data.heatonresearch.com (data.heatonresearch.com)|52.84.125.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75374 (74K) [image/jpeg]\n",
      "Saving to: ‘/content/images/sidewalk4.jpg’\n",
      "\n",
      "/content/images/sid 100%[===================>]  73.61K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-02-27 01:22:49 (4.70 MB/s) - ‘/content/images/sidewalk4.jpg’ saved [75374/75374]\n",
      "\n",
      "--2024-02-27 01:22:49--  https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.jpg\n",
      "Resolving data.heatonresearch.com (data.heatonresearch.com)... 52.84.125.38, 52.84.125.18, 52.84.125.73, ...\n",
      "Connecting to data.heatonresearch.com (data.heatonresearch.com)|52.84.125.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 95239 (93K) [image/jpeg]\n",
      "Saving to: ‘/content/images/sidewalk5.jpg’\n",
      "\n",
      "/content/images/sid 100%[===================>]  93.01K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-02-27 01:22:49 (5.09 MB/s) - ‘/content/images/sidewalk5.jpg’ saved [95239/95239]\n",
      "\n",
      "--2024-02-27 01:22:49--  https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.jpg\n",
      "Resolving data.heatonresearch.com (data.heatonresearch.com)... 52.84.125.38, 52.84.125.18, 52.84.125.73, ...\n",
      "Connecting to data.heatonresearch.com (data.heatonresearch.com)|52.84.125.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 93111 (91K) [image/jpeg]\n",
      "Saving to: ‘/content/images/sidewalk6.jpg’\n",
      "\n",
      "/content/images/sid 100%[===================>]  90.93K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-02-27 01:22:49 (5.47 MB/s) - ‘/content/images/sidewalk6.jpg’ saved [93111/93111]\n",
      "\n",
      "--2024-02-27 01:22:50--  https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.jpg\n",
      "Resolving data.heatonresearch.com (data.heatonresearch.com)... 52.84.125.38, 52.84.125.18, 52.84.125.73, ...\n",
      "Connecting to data.heatonresearch.com (data.heatonresearch.com)|52.84.125.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 95720 (93K) [image/jpeg]\n",
      "Saving to: ‘/content/images/sidewalk7.jpg’\n",
      "\n",
      "/content/images/sid 100%[===================>]  93.48K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-02-27 01:22:50 (4.34 MB/s) - ‘/content/images/sidewalk7.jpg’ saved [95720/95720]\n",
      "\n",
      "--2024-02-27 01:22:50--  https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.jpg\n",
      "Resolving data.heatonresearch.com (data.heatonresearch.com)... 52.84.125.38, 52.84.125.18, 52.84.125.73, ...\n",
      "Connecting to data.heatonresearch.com (data.heatonresearch.com)|52.84.125.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 90596 (88K) [image/jpeg]\n",
      "Saving to: ‘/content/images/sidewalk8.jpg’\n",
      "\n",
      "/content/images/sid 100%[===================>]  88.47K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-02-27 01:22:50 (6.11 MB/s) - ‘/content/images/sidewalk8.jpg’ saved [90596/90596]\n",
      "\n",
      "--2024-02-27 01:22:50--  https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.jpg\n",
      "Resolving data.heatonresearch.com (data.heatonresearch.com)... 52.84.125.38, 52.84.125.18, 52.84.125.73, ...\n",
      "Connecting to data.heatonresearch.com (data.heatonresearch.com)|52.84.125.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 70838 (69K) [image/jpeg]\n",
      "Saving to: ‘/content/images/sidewalk9.jpg’\n",
      "\n",
      "/content/images/sid 100%[===================>]  69.18K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-02-27 01:22:50 (4.37 MB/s) - ‘/content/images/sidewalk9.jpg’ saved [70838/70838]\n",
      "\n",
      "--2024-02-27 01:22:50--  https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.jpg\n",
      "Resolving data.heatonresearch.com (data.heatonresearch.com)... 52.84.125.38, 52.84.125.18, 52.84.125.73, ...\n",
      "Connecting to data.heatonresearch.com (data.heatonresearch.com)|52.84.125.38|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 51849 (51K) [image/jpeg]\n",
      "Saving to: ‘/content/images/sidewalk10.jpg’\n",
      "\n",
      "/content/images/sid 100%[===================>]  50.63K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2024-02-27 01:22:50 (2.67 MB/s) - ‘/content/images/sidewalk10.jpg’ saved [51849/51849]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /content/images\n",
    "!wget -O /content/images/sidewalk1.jpg https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk1.jpg\n",
    "!wget -O /content/images/sidewalk2.jpg https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk2.jpg\n",
    "!wget -O /content/images/sidewalk3.jpg https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk3.jpg\n",
    "!wget -O /content/images/sidewalk4.jpg https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk4.jpg\n",
    "!wget -O /content/images/sidewalk5.jpg https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk5.jpg\n",
    "!wget -O /content/images/sidewalk6.jpg https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk6.jpg\n",
    "!wget -O /content/images/sidewalk7.jpg https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk7.jpg\n",
    "!wget -O /content/images/sidewalk8.jpg https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk8.jpg\n",
    "!wget -O /content/images/sidewalk9.jpg https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk9.jpg\n",
    "!wget -O /content/images/sidewalk10.jpg https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk10.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17628,
     "status": "ok",
     "timestamp": 1708997621317,
     "user": {
      "displayName": "hanhans Han",
      "userId": "17100325406789429061"
     },
     "user_tz": 360
    },
    "id": "BTAqzYf5Ie27",
    "outputId": "166683c5-1d86-4e9e-9733-6e564e8c8645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=/content/images/, data=yolov5/data/coco128.yaml, imgsz=[900, 900], conf_thres=0.1, iou_thres=0.25, max_det=1000, device=, view_img=False, save_txt=True, save_csv=False, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 🚀 v7.0-287-g574331f9 Python-3.10.12 torch-2.1.0+cu121 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "WARNING ⚠️ --img-size [900, 900] must be multiple of max stride 32, updating to [928, 928]\n",
      "image 1/10 /content/images/sidewalk1.jpg: 512x928 12 persons, 7 cars, 1 motorcycle, 1 bus, 1 boat, 2 benchs, 2 umbrellas, 1 suitcase, 821.6ms\n",
      "image 2/10 /content/images/sidewalk10.jpg: 512x928 29 persons, 1 bicycle, 1 car, 1 dog, 1 suitcase, 701.6ms\n",
      "image 3/10 /content/images/sidewalk2.jpg: 512x928 25 persons, 2 cars, 1 motorcycle, 2 boats, 2 benchs, 5 umbrellas, 813.6ms\n",
      "image 4/10 /content/images/sidewalk3.jpg: 512x928 25 persons, 2 umbrellas, 1 kite, 529.8ms\n",
      "image 5/10 /content/images/sidewalk4.jpg: 512x928 28 persons, 1 bicycle, 2 cars, 5 motorcycles, 1 bus, 4 umbrellas, 535.7ms\n",
      "image 6/10 /content/images/sidewalk5.jpg: 512x928 28 persons, 3 bicycles, 1 car, 5 umbrellas, 560.7ms\n",
      "image 7/10 /content/images/sidewalk6.jpg: 512x928 52 persons, 1 bicycle, 1 car, 2 motorcycles, 1 bus, 2 boats, 5 umbrellas, 497.1ms\n",
      "image 8/10 /content/images/sidewalk7.jpg: 512x928 36 persons, 1 car, 3 boats, 2 horses, 1 cow, 1 elephant, 5 umbrellas, 501.7ms\n",
      "image 9/10 /content/images/sidewalk8.jpg: 512x928 42 persons, 3 motorcycles, 1 train, 2 boats, 2 horses, 3 umbrellas, 521.5ms\n",
      "image 10/10 /content/images/sidewalk9.jpg: 512x928 33 persons, 1 motorcycle, 1 traffic light, 1 stop sign, 1 horse, 3 umbrellas, 557.3ms\n",
      "Speed: 2.1ms pre-process, 604.1ms inference, 5.4ms NMS per image at shape (1, 3, 928, 928)\n",
      "Results saved to \u001b[1myolov5/runs/detect/exp9\u001b[0m\n",
      "10 labels saved to yolov5/runs/detect/exp9/labels\n"
     ]
    }
   ],
   "source": [
    "!python yolov5/detect.py --weights yolov5s.pt --img 900  \\\n",
    "  --conf 0.1 --iou-thres 0.25 --source /content/images/ --save-txt --save-conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88,
     "status": "ok",
     "timestamp": 1708997634691,
     "user": {
      "displayName": "hanhans Han",
      "userId": "17100325406789429061"
     },
     "user_tz": 360
    },
    "id": "IeUcf9-bI_zy",
    "outputId": "e887c4cf-0c3c-44e8-c069-c1db275241fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image  person  car  bicycle  motorbike  umbrella  handbag\n",
      "0      1      11    5        0          2         0        0\n",
      "1      2      21    3        0          1         0        0\n",
      "2      3      20    0        0          0         0        0\n",
      "3      4      25    0        1          3         0        0\n",
      "4      5      27    3        4          0         0        0\n",
      "5      6      36    1        1          2         0        0\n",
      "6      7      37    0        0          0         0        0\n",
      "7      8      31    0        1          0         0        0\n",
      "8      9      36    0        0          0         0        0\n",
      "9     10      27    1        1          0         0        0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "labels_dir = 'yolov5/runs/detect/exp8/labels'\n",
    "\n",
    "categories = {0: 'person', 2: 'car', 1: 'bicycle', 3: 'motorbike', 26: 'umbrella', 27: 'handbag'}\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for file_name in os.listdir(labels_dir):\n",
    "    if file_name.endswith('.txt'):\n",
    "\n",
    "        image_id = int(file_name.split('.')[0].replace('sidewalk', ''))\n",
    "\n",
    "\n",
    "        with open(os.path.join(labels_dir, file_name), 'r') as file:\n",
    "            detections = file.readlines()\n",
    "\n",
    "\n",
    "        counts = Counter()\n",
    "        for det in detections:\n",
    "            class_id, conf = det.split()[:2]\n",
    "            class_id = int(class_id)\n",
    "            if class_id in categories:\n",
    "                counts[categories[class_id]] += 1\n",
    "\n",
    "\n",
    "        result = {'image': image_id}\n",
    "        result.update(counts)\n",
    "        results.append(result)\n",
    "\n",
    "df_columns = ['image', 'person', 'car', 'bicycle', 'motorbike', 'umbrella', 'handbag']\n",
    "df = pd.DataFrame(results, columns=df_columns).fillna(0).astype(int)\n",
    "\n",
    "submit_df = df.sort_values('image').reset_index(drop=True)\n",
    "\n",
    "print(submit_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1709240767501,
     "user": {
      "displayName": "hanhans Han",
      "userId": "17100325406789429061"
     },
     "user_tz": 360
    },
    "id": "UCR4XqGODB0a"
   },
   "outputs": [],
   "source": [
    "\n",
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - List of pandas dataframes or images.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    payload = []\n",
    "    for item in data:\n",
    "        if type(item) is PIL.Image.Image:\n",
    "            buffered = BytesIO()\n",
    "            item.save(buffered, format=\"PNG\")\n",
    "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
    "        elif type(item) is pd.core.frame.DataFrame:\n",
    "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
    "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code==200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1708997637564,
     "user": {
      "displayName": "hanhans Han",
      "userId": "17100325406789429061"
     },
     "user_tz": 360
    },
    "id": "Mhwc8WLfDDNE",
    "outputId": "7c69c6dc-a0c1-4742-8f63-e9567a406fd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Submitted Assignment 5 for luozihan:\n",
      "You have submitted this assignment 6 times. (this is fine)\n",
      "Warning: The mean of column 'person' differs from the solution file by 16.700000000000003. (might not matter if small)\n",
      "Warning: The mean of column 'car' differs from the solution file by 0.4. (might not matter if small)\n",
      "Warning: The mean of column 'bicycle' differs from the solution file by 0.7000000000000001. (might not matter if small)\n",
      "Warning: The mean of column 'motorbike' differs from the solution file by 0.8. (might not matter if small)\n",
      "Warning: The mean of column 'umbrella' differs from the solution file by 2.2. (might not matter if small)\n",
      "Warnings were identified, these may or may not matter to get full credit for this assignment.\n"
     ]
    }
   ],
   "source": [
    "key = \"QGOMi9jY948rtuqknQ9Wb20gQ7BaRlg369Q6fiSX\"\n",
    "\n",
    "# You must also identify your source file.  (modify for your local setup)\n",
    "file='/content/drive/MyDrive/Colab Notebooks/assignment_solution_class5.ipynb'  # Google CoLab\n",
    "\n",
    "submit(source_file=file,data=[submit_df],key=key,no=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36909,
     "status": "ok",
     "timestamp": 1709240566214,
     "user": {
      "displayName": "hanhans Han",
      "userId": "17100325406789429061"
     },
     "user_tz": 360
    },
    "id": "xwuq9Z3Nq4v9",
    "outputId": "f1bf12fd-1129-4b67-8194-5cf0d15e3044"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/hub.py:294: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['gitpython>=3.1.30'] not found, attempting AutoUpdate...\n",
      "Collecting gitpython>=3.1.30\n",
      "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 195.4/195.4 kB 4.9 MB/s eta 0:00:00\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 21.8 MB/s eta 0:00:00\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, gitdb, gitpython\n",
      "Successfully installed gitdb-4.0.11 gitpython-3.1.42 smmap-5.0.1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 7.4s, installed 1 package: ['gitpython>=3.1.30']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 2024-2-29 Python-3.10.12 torch-2.1.0+cu121 CPU\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|██████████| 14.1M/14.1M [00:00<00:00, 164MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image  person  car  bicycle  motorbike  umbrella  handbag\n",
      "0      1       8    2        0          0         0        0\n",
      "1      2      12    4        0          0         0        0\n",
      "2      3       1    0        0          0         0        0\n",
      "3      4      15    0        0          0         0        0\n",
      "4      5      13    1        1          0         0        0\n",
      "5      6       9    2        0          1         0        0\n",
      "6      7      11    0        0          0         0        0\n",
      "7      8      12    0        0          0         0        0\n",
      "8      9       8    0        0          0         0        0\n",
      "9     10      15    0        0          0         0        0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for i in range(1, 11):\n",
    "    url = f\"https://data.heatonresearch.com/data/t81-558/sidewalk/sidewalk{i}.jpg\"\n",
    "    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "\n",
    "\n",
    "    infer_results = yolo_model(img)\n",
    "\n",
    "\n",
    "    df = infer_results.pandas().xyxy[0]\n",
    "\n",
    "\n",
    "    categories = {0: 'person', 2: 'car', 1: 'bicycle', 3: 'motorbike', 26: 'umbrella', 27: 'handbag'}\n",
    "    counts = Counter()\n",
    "    for index, row in df.iterrows():\n",
    "        if row['class'] in categories:\n",
    "            counts[categories[row['class']]] += 1\n",
    "\n",
    "    result = {'image': i}\n",
    "    result.update(counts)\n",
    "    results.append(result)\n",
    "\n",
    "\n",
    "df_columns = ['image', 'person', 'car', 'bicycle', 'motorbike', 'umbrella', 'handbag']\n",
    "submit_df = pd.DataFrame(results, columns=df_columns).fillna(0).astype(int)\n",
    "\n",
    "print(submit_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4665,
     "status": "ok",
     "timestamp": 1709240912846,
     "user": {
      "displayName": "hanhans Han",
      "userId": "17100325406789429061"
     },
     "user_tz": 360
    },
    "id": "mLb2ZGeGr6Ba",
    "outputId": "c167b46d-3a3f-4e4e-baf3-896b3f4375ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Submitted Assignment 5 for luozihan:\n",
      "You have submitted this assignment 7 times. (this is fine)\n",
      "Warning: The mean of column 'motorbike' differs from the solution file by 0.1. (might not matter if small)\n",
      "Warning: The mean of column 'umbrella' differs from the solution file by 2.2. (might not matter if small)\n",
      "Warnings were identified, these may or may not matter to get full credit for this assignment.\n"
     ]
    }
   ],
   "source": [
    "key = \"QGOMi9jY948rtuqknQ9Wb20gQ7BaRlg369Q6fiSX\"\n",
    "\n",
    "# You must also identify your source file.  (modify for your local setup)\n",
    "file='/content/drive/MyDrive/Colab Notebooks/assignment_solution_class5.ipynb'  # Google CoLab\n",
    "\n",
    "submit(source_file=file,data=[submit_df],key=key,no=5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNE75AmigxiswmqLCWjSevz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
