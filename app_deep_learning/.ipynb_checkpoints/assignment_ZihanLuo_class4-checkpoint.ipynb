{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb47193",
   "metadata": {
    "id": "LtZEPBbW0A1p"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bbd3f1",
   "metadata": {
    "id": "4AGR8dD60A1q"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
    "\n",
    "**Module 4 Assignment: Classification and Regression Neural Network**\n",
    "\n",
    "**Student Name: Your Name**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd5b6e",
   "metadata": {
    "id": "EjjWZ6js0A1r"
   },
   "source": [
    "# Assignment Instructions\n",
    "\n",
    "For this assignment, you will use the **crx.csv** dataset.  This dataset is a public dataset that can you can find [here](https://archive.ics.uci.edu/ml/datasets/credit+approval). You should use the CSV file on my data site, at this location: [crx.csv](https://data.heatonresearch.com/data/t81-558/crx.csv) because it includes column headers.  The primary use for this dataset is binary classification. There are 15 attributes, plus a target column that contains only + or -.  Some of the columns have missing values.\n",
    "\n",
    "You should train a neural network and return the predictions.  You will submit these predictions to the **submit** function.  See [Assignment #1](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class1.ipynb) for details on how to submit an assignment or check that one was submitted.\n",
    "\n",
    "Complete the following tasks:\n",
    "\n",
    "* Your task is to replace missing values in columns *a2* and *a14* with values estimated by a neural network (one neural network for *a2* and another for *a14*).\n",
    "* Your submission file will contain the same headers as the source CSV: *a1*, *a2*, *s3*, *a4*, *a5*, *a6*, *a7*, *a8*, *a9*, *a10*, *a11*, *a12*, *a13*, *a14*, *a15*, and *a16*.\n",
    "* You should only need to modify *a2* and *a14*.\n",
    "* Neural networks can be much more powerful at filling missing variables than median and mean.\n",
    "* Train two neural networks to predict *a2* and *a14*.  \n",
    "* The *y* (target) for training the two nets will be *a2* and *a14*, depending on which you are trying to fill.\n",
    "* The x for training the two nets will be 's3','a8','a9','a10','a11','a12','a13','a15'.  These are chosen because it is important not to use any columns with missing values; also, it could cause unwanted bias if we include the ultimate target (*a16*).\n",
    "* ONLY predict new values for missing values in *a2* and *a14*.\n",
    "* You will likely get this small warning:  Warning: The mean of column a14 differs from the solution file by 0.20238937709643778. (might not matter if small)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6b5d56",
   "metadata": {
    "id": "kFOmkNMN0A1r"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dac4c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXzFrMZc0A1r",
    "outputId": "76715f6c-3fb7-4b4e-e5cd-43014bc99d5f"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "\n",
    "# Early stopping (see module 3.4)\n",
    "import copy\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif self.best_loss - val_loss >= self.min_delta:\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}\"\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement in the last {self.counter} epochs\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# Make use of a GPU or MPS (Apple) if one is available.  (see module 3.2)\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"mps\"\n",
    "    if getattr(torch, \"has_mps\", False)\n",
    "    else \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba099b",
   "metadata": {
    "id": "N8l6b87y0A1t"
   },
   "source": [
    "# Assignment Submit Function\n",
    "\n",
    "You will submit the ten programming assignments electronically.  The following **submit** function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any underlying problems.\n",
    "\n",
    "**It is unlikely that should need to modify this function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a922da74",
   "metadata": {
    "id": "9T6mAmM50A1t"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - List of pandas dataframes or images.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    payload = []\n",
    "    for item in data:\n",
    "        if type(item) is PIL.Image.Image:\n",
    "            buffered = BytesIO()\n",
    "            item.save(buffered, format=\"PNG\")\n",
    "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
    "        elif type(item) is pd.core.frame.DataFrame:\n",
    "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
    "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code==200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c24ce6",
   "metadata": {
    "collapsed": true,
    "id": "iKv-IaUK0A1t"
   },
   "source": [
    "# Assignment #4 Sample Code\n",
    "\n",
    "The following code provides a starting point for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc485a",
   "metadata": {
    "id": "mguSM-9C0A1t"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# This is your student key that I emailed to you at the beginnning of the semester.\n",
    "key = \"H3B554uPhc3f8kirGGBYA7cYuDOamhXM87OY6QH1\"  # This is an example key and will not work.\n",
    "key = \"uTtH5yNbPs9tZdRWsBf9V9FaQA9RU2iP5cL7F3zH\"\n",
    "\n",
    "\n",
    "# You must also identify your source file.  (modify for your local setup)\n",
    "file='/content/drive/My Drive/Colab Notebooks/assignment_solution_class4.ipynb'  # Google CoLab\n",
    "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class4.ipynb'  # Windows\n",
    "# file='/Users/jeff/projects/t81_558_deep_learning/assignments/assignment_yourname_class4.ipynb'  # Mac/Linux\n",
    "\n",
    "# Begin assignment\n",
    "df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/crx.csv\",na_values=['?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d99b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7nhJr_i0A1u",
    "outputId": "5e898135-a70c-4fb0-ecd3-634524045c4c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def fill_missing_numeric(df, current, target):\n",
    "    pass\n",
    "\n",
    "df_submit = fill_missing_numeric(df, 'a2', 'a16')\n",
    "df_submit = fill_missing_numeric(df_submit, 'a14', 'a16')\n",
    "\n",
    "submit(source_file=file,data=[df_submit],key=key,no=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb982b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# T81-558: Applications of Deep Neural Networks\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
    "\n",
    "**Module 4 Assignment: Classification and Regression Neural Network**\n",
    "\n",
    "**Student Name: Your Name**\n",
    "\n",
    "# Assignment Instructions\n",
    "\n",
    "For this assignment, you will use the **crx.csv** dataset.  This dataset is a public dataset that can you can find [here](https://archive.ics.uci.edu/ml/datasets/credit+approval). You should use the CSV file on my data site, at this location: [crx.csv](https://data.heatonresearch.com/data/t81-558/crx.csv) because it includes column headers.  The primary use for this dataset is binary classification. There are 15 attributes, plus a target column that contains only + or -.  Some of the columns have missing values.\n",
    "\n",
    "You should train a neural network and return the predictions.  You will submit these predictions to the **submit** function.  See [Assignment #1](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class1.ipynb) for details on how to submit an assignment or check that one was submitted.\n",
    "\n",
    "Complete the following tasks:\n",
    "\n",
    "* Your task is to replace missing values in columns *a2* and *a14* with values estimated by a neural network (one neural network for *a2* and another for *a14*).\n",
    "* Your submission file will contain the same headers as the source CSV: *a1*, *a2*, *s3*, *a4*, *a5*, *a6*, *a7*, *a8*, *a9*, *a10*, *a11*, *a12*, *a13*, *a14*, *a15*, and *a16*.\n",
    "* You should only need to modify *a2* and *a14*.\n",
    "* Neural networks can be much more powerful at filling missing variables than median and mean.\n",
    "* Train two neural networks to predict *a2* and *a14*.  \n",
    "* The *y* (target) for training the two nets will be *a2* and *a14*, depending on which you are trying to fill.\n",
    "* The x for training the two nets will be 's3','a8','a9','a10','a11','a12','a13','a15'.  These are chosen because it is important not to use any columns with missing values; also, it could cause unwanted bias if we include the ultimate target (*a16*).\n",
    "* ONLY predict new values for missing values in *a2* and *a14*.\n",
    "* You will likely get this small warning:  Warning: The mean of column a14 differs from the solution file by 0.20238937709643778. (might not matter if small)\n",
    "\n",
    "\n",
    "\n",
    "# Google CoLab Instructions\n",
    "\n",
    "If you are using Google CoLab, it will be necessary to mount your GDrive so that you can send your notebook during the submit process. Running the following code will map your GDrive to ```/content/drive```.\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "\n",
    "# Early stopping (see module 3.4)\n",
    "import copy\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif self.best_loss - val_loss >= self.min_delta:\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}\"\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement in the last {self.counter} epochs\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# Make use of a GPU or MPS (Apple) if one is available.  (see module 3.2)\n",
    "import torch\n",
    "\n",
    "device = (\n",
    "    \"mps\"\n",
    "    if getattr(torch, \"has_mps\", False)\n",
    "    else \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Assignment Submit Function\n",
    "\n",
    "You will submit the ten programming assignments electronically.  The following **submit** function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any underlying problems.\n",
    "\n",
    "**It is unlikely that should need to modify this function.**\n",
    "\n",
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - List of pandas dataframes or images.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    payload = []\n",
    "    for item in data:\n",
    "        if type(item) is PIL.Image.Image:\n",
    "            buffered = BytesIO()\n",
    "            item.save(buffered, format=\"PNG\")\n",
    "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
    "        elif type(item) is pd.core.frame.DataFrame:\n",
    "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
    "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code==200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))\n",
    "\n",
    "# Assignment #4 Sample Code\n",
    "\n",
    "The following code provides a starting point for this assignment.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# This is your student key that I emailed to you at the beginnning of the semester.\n",
    "key = \"H3B554uPhc3f8kirGGBYA7cYuDOamhXM87OY6QH1\"  # This is an example key and will not work.\n",
    "key = \"uTtH5yNbPs9tZdRWsBf9V9FaQA9RU2iP5cL7F3zH\"\n",
    "\n",
    "\n",
    "# You must also identify your source file.  (modify for your local setup)\n",
    "file='/content/drive/My Drive/Colab Notebooks/assignment_solution_class4.ipynb'  # Google CoLab\n",
    "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_yourname_class4.ipynb'  # Windows\n",
    "# file='/Users/jeff/projects/t81_558_deep_learning/assignments/assignment_yourname_class4.ipynb'  # Mac/Linux\n",
    "\n",
    "# Begin assignment\n",
    "df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/crx.csv\",na_values=['?'])\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def fill_missing_numeric(df, current, target):\n",
    "    pass\n",
    "\n",
    "df_submit = fill_missing_numeric(df, 'a2', 'a16')\n",
    "df_submit = fill_missing_numeric(df_submit, 'a14', 'a16')\n",
    "\n",
    "submit(source_file=file,data=[df_submit],key=key,no=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317657b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "129f9842",
   "metadata": {},
   "source": [
    "# Assignment #4 MyCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f7484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - List of pandas dataframes or images.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.\n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    payload = []\n",
    "    for item in data:\n",
    "        if type(item) is PIL.Image.Image:\n",
    "            buffered = BytesIO()\n",
    "            item.save(buffered, format=\"PNG\")\n",
    "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
    "        elif type(item) is pd.core.frame.DataFrame:\n",
    "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
    "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code==200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1651dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "key = \"QGOMi9jY948rtuqknQ9Wb20gQ7BaRlg369Q6fiSX\" \n",
    "file='E:\\\\WUSTL\\\\2024 SPRING\\\\INFO.558 Applications of Deep Neural Networks\\\\jheaton\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_ZihanLuo_class4.ipynb'\n",
    "\n",
    "df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/crx.csv\",na_values=['?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff5dbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>s3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>a10</th>\n",
       "      <th>a11</th>\n",
       "      <th>a12</th>\n",
       "      <th>a13</th>\n",
       "      <th>a14</th>\n",
       "      <th>a15</th>\n",
       "      <th>a16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.250</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.040</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.750</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.710</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "      <td>32.08</td>\n",
       "      <td>4.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>2.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>33.17</td>\n",
       "      <td>1.040</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>r</td>\n",
       "      <td>h</td>\n",
       "      <td>6.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>164.0</td>\n",
       "      <td>31285</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>22.92</td>\n",
       "      <td>11.585</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1349</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b</td>\n",
       "      <td>54.42</td>\n",
       "      <td>0.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>h</td>\n",
       "      <td>3.960</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>180.0</td>\n",
       "      <td>314</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b</td>\n",
       "      <td>42.50</td>\n",
       "      <td>4.915</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.165</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1442</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b</td>\n",
       "      <td>22.08</td>\n",
       "      <td>0.830</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>2.165</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b</td>\n",
       "      <td>29.92</td>\n",
       "      <td>1.835</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>4.335</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>260.0</td>\n",
       "      <td>200</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a</td>\n",
       "      <td>38.25</td>\n",
       "      <td>6.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>1.000</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b</td>\n",
       "      <td>48.08</td>\n",
       "      <td>6.040</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2690</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a</td>\n",
       "      <td>45.83</td>\n",
       "      <td>10.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>v</td>\n",
       "      <td>5.000</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>7</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>b</td>\n",
       "      <td>36.67</td>\n",
       "      <td>4.415</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.250</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>10</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b</td>\n",
       "      <td>28.25</td>\n",
       "      <td>0.875</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>0.960</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>3</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>396.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a</td>\n",
       "      <td>23.25</td>\n",
       "      <td>5.875</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>v</td>\n",
       "      <td>3.170</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>10</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>120.0</td>\n",
       "      <td>245</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>b</td>\n",
       "      <td>21.83</td>\n",
       "      <td>0.250</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>0.665</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a</td>\n",
       "      <td>19.17</td>\n",
       "      <td>8.585</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>h</td>\n",
       "      <td>0.750</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>7</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a1     a2      s3 a4 a5  a6 a7     a8 a9 a10  a11 a12 a13    a14    a15 a16\n",
       "0   b  30.83   0.000  u  g   w  v  1.250  t   t    1   f   g  202.0      0   +\n",
       "1   a  58.67   4.460  u  g   q  h  3.040  t   t    6   f   g   43.0    560   +\n",
       "2   a  24.50   0.500  u  g   q  h  1.500  t   f    0   f   g  280.0    824   +\n",
       "3   b  27.83   1.540  u  g   w  v  3.750  t   t    5   t   g  100.0      3   +\n",
       "4   b  20.17   5.625  u  g   w  v  1.710  t   f    0   f   s  120.0      0   +\n",
       "5   b  32.08   4.000  u  g   m  v  2.500  t   f    0   t   g  360.0      0   +\n",
       "6   b  33.17   1.040  u  g   r  h  6.500  t   f    0   t   g  164.0  31285   +\n",
       "7   a  22.92  11.585  u  g  cc  v  0.040  t   f    0   f   g   80.0   1349   +\n",
       "8   b  54.42   0.500  y  p   k  h  3.960  t   f    0   f   g  180.0    314   +\n",
       "9   b  42.50   4.915  y  p   w  v  3.165  t   f    0   t   g   52.0   1442   +\n",
       "10  b  22.08   0.830  u  g   c  h  2.165  f   f    0   t   g  128.0      0   +\n",
       "11  b  29.92   1.835  u  g   c  h  4.335  t   f    0   f   g  260.0    200   +\n",
       "12  a  38.25   6.000  u  g   k  v  1.000  t   f    0   t   g    0.0      0   +\n",
       "13  b  48.08   6.040  u  g   k  v  0.040  f   f    0   f   g    0.0   2690   +\n",
       "14  a  45.83  10.500  u  g   q  v  5.000  t   t    7   t   g    0.0      0   +\n",
       "15  b  36.67   4.415  y  p   k  v  0.250  t   t   10   t   g  320.0      0   +\n",
       "16  b  28.25   0.875  u  g   m  v  0.960  t   t    3   t   g  396.0      0   +\n",
       "17  a  23.25   5.875  u  g   q  v  3.170  t   t   10   f   g  120.0    245   +\n",
       "18  b  21.83   0.250  u  g   d  h  0.665  t   f    0   t   g    0.0      0   +\n",
       "19  a  19.17   8.585  u  g  cc  h  0.750  t   t    7   f   g   96.0      0   +"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "994347fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif self.best_loss - val_loss >= self.min_delta:\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}\"\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement in the last {self.counter} epochs\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa40e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6484d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luozi\\AppData\\Local\\Temp\\ipykernel_17048\\3493329693.py:3: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  if getattr(torch, \"has_mps\", False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = (\n",
    "    \"mps\"\n",
    "    if getattr(torch, \"has_mps\", False)\n",
    "    else \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f312516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "def fill_missing_numeric(df, current, target):\n",
    "    device = 'cuda'\n",
    "    df_copy = df.copy()  \n",
    "    df_dummies = pd.get_dummies(df[['a1', 'a4', 'a5', 'a6', 'a7', 'a9', 'a10', 'a12', 'a13']]).astype(int)\n",
    "    df = pd.concat([df, df_dummies], axis=1)\n",
    "    \n",
    "    df_with_target = df.dropna(subset=[current])\n",
    "    df_without_target = df[df[current].isna()]\n",
    "    \n",
    "    x_columns = df_with_target.columns.drop(['a1', 'a4', 'a5', 'a6', 'a7', 'a9', 'a10', 'a12', 'a13',target, current])\n",
    "    X = df_with_target[x_columns].values\n",
    "    y = df_with_target[current].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "    X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    " \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in kf.split(X_tensor):\n",
    "       \n",
    "        x_train, x_test = X_tensor[train_idx], X_tensor[test_idx]\n",
    "        y_train, y_test = y_tensor[train_idx], y_tensor[test_idx]\n",
    "\n",
    "      \n",
    "        train_dataset = TensorDataset(x_train, y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "    \n",
    "        model = model.to(device)\n",
    "    \n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        loss_fn = nn.MSELoss()\n",
    "    \n",
    "        # Early Stopping variables\n",
    "        best_loss = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "\n",
    "        # Training loop\n",
    "        EPOCHS = 500\n",
    "        epoch = 0\n",
    "        done = False\n",
    "        es = EarlyStopping()\n",
    "        \n",
    "        while not done and epoch<EPOCHS:\n",
    "            epoch += 1\n",
    "            model.train()\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.to(device)  \n",
    "                y_batch = y_batch.to(device) \n",
    "                optimizer.zero_grad()\n",
    "                output = model(x_batch)\n",
    "                loss = loss_fn(output, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x_test = x_test.to(device)\n",
    "            val_output = model(x_test)\n",
    "            val_loss = loss_fn(val_output, y_test.to(device))\n",
    "\n",
    "        if es(model, val_loss):\n",
    "            done = True\n",
    "        \n",
    "        if not df_without_target.empty:\n",
    "            X_missing = df_without_target[x_columns].values\n",
    "            X_missing_scaled = scaler.transform(X_missing)\n",
    "            X_missing_tensor = torch.tensor(X_missing_scaled, dtype=torch.float32).to(device)  # 确保数据在正确的设备上\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                predicted_values = model(X_missing_tensor).cpu().numpy().flatten()  # 将预测结果移回CPU并转为NumPy数组\n",
    "        \n",
    "            df_copy.loc[df_without_target.index, current] = predicted_values\n",
    "    \n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "df_submit  = fill_missing_numeric(df, 'a2', 'a16')\n",
    "df_submit  = fill_missing_numeric(df_submit, 'a14', 'a16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc7bb4cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Submitted Assignment 4 for luozihan:\n",
      "You have submitted this assignment 4 times. (this is fine)\n",
      "Note: The mean difference 0.0 for column 'a2' is acceptable and is less than the maximum allowed value of '1.0' for this assignment.\n",
      "Note: The mean difference 0.8307530712372397 for column 'a14' is acceptable and is less than the maximum allowed value of '1.0' for this assignment.\n",
      "No warnings or errors (only notes), you will probably do well, but no guarantee. :-)\n"
     ]
    }
   ],
   "source": [
    "submit(source_file=file,data=[df_submit],key=key,no=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
