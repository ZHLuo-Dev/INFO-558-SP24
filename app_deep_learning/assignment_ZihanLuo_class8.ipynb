{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "domrnonINuu4"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTAVwaaOFuEf"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/academics/programs/index.html)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n",
    "\n",
    "**Module 8 Assignment: Feature Engineering**\n",
    "\n",
    "**Student Name: Your Name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YUdI4CcFuEg"
   },
   "source": [
    "# Assignment Instructions\n",
    "\n",
    "This assignment is similar to assignment 5, except that you must use feature engineering to solve it.  I provide you with a dataset that contains dimensions and the quality of items of specific shapes.  With the values of 'height', 'width', 'depth'. 'shape', and 'quality' you should try to predict the cost of these items.  You should be able to match very close to solution file, if you feature engineer correctly.  To get full credit your average cost should not be more than 50 off from the solution.  The autocorrector will let you know if you are in this range.\n",
    "\n",
    "You can find all of the needed CSV files here:\n",
    "\n",
    "* [Shapes - Training](https://data.heatonresearch.com/data/t81-558/datasets/shapes-train.csv)\n",
    "* [Shapes - Submit](https://data.heatonresearch.com/data/t81-558/datasets/shapes-test.csv)\n",
    "\n",
    "Use the training file to train your neural network and submit results for for the data contained in the test/submit file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9ZvFFOR5A-Wo",
    "outputId": "79139a73-499a-47fd-e623-cfbd26c8f9f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Note: using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qrsT_KZFuEh"
   },
   "source": [
    "# Assignment Submit Function\n",
    "\n",
    "You will submit the 10 programming assignments electronically.  The following submit function can be used to do this.  My server will perform a basic check of each assignment and let you know if it sees any basic problems. \n",
    "\n",
    "**It is unlikely that should need to modify this function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "43KOAL0OFuEi"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
    "# submission counts.  The paramaters are as follows:\n",
    "# data - List of pandas dataframes or images.\n",
    "# key - Your student key that was emailed to you.\n",
    "# no - The assignment class number, should be 1 through 1.\n",
    "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
    "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
    "def submit(data,key,no,source_file=None):\n",
    "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
    "    if source_file is None: source_file = __file__\n",
    "    suffix = '_class{}'.format(no)\n",
    "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
    "    with open(source_file, \"rb\") as image_file:\n",
    "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
    "    ext = os.path.splitext(source_file)[-1].lower()\n",
    "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
    "    payload = []\n",
    "    for item in data:\n",
    "        if type(item) is PIL.Image.Image:\n",
    "            buffered = BytesIO()\n",
    "            item.save(buffered, format=\"PNG\")\n",
    "            payload.append({'PNG':base64.b64encode(buffered.getvalue()).decode('ascii')})\n",
    "        elif type(item) is pd.core.frame.DataFrame:\n",
    "            payload.append({'CSV':base64.b64encode(item.to_csv(index=False).encode('ascii')).decode(\"ascii\")})\n",
    "    r= requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
    "        headers={'x-api-key':key}, json={ 'payload': payload,'assignment': no, 'ext':ext, 'py':encoded_python})\n",
    "    if r.status_code==200:\n",
    "        print(\"Success: {}\".format(r.text))\n",
    "    else: print(\"Failure: {}\".format(r.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "zd5fX98YFuEm"
   },
   "source": [
    "# Assignment #8 MyCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lIB3MmKuFuEn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "key = \"QGOMi9jY948rtuqknQ9Wb20gQ7BaRlg369Q6fiSX\" \n",
    "file='E:\\\\WUSTL\\\\2024 SPRING\\\\INFO.558 Applications of Deep Neural Networks\\\\jheaton\\\\projects\\\\t81_558_deep_learning\\\\assignments\\\\assignment_ZihanLuo_class8.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=50, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif self.best_loss - val_loss >= self.min_delta:\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}\"\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement in the last {self.counter} epochs\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, tloss: 127443.2109375, vloss: 331873.3750: 100%|██████████| 469/469 [00:00<00:00, 830.25it/s]\n",
      "Epoch: 2, tloss: 59230.0859375, vloss: 92630.5234: 100%|██████████| 469/469 [00:00<00:00, 878.38it/s]\n",
      "Epoch: 3, tloss: 69751.96875, vloss: 56818.5195: 100%|██████████| 469/469 [00:00<00:00, 818.47it/s]\n",
      "Epoch: 4, tloss: 30921.62890625, vloss: 39249.3672: 100%|██████████| 469/469 [00:00<00:00, 843.14it/s]\n",
      "Epoch: 5, tloss: 9221.54296875, vloss: 47240.8633: 100%|██████████| 469/469 [00:00<00:00, 808.51it/s]\n",
      "Epoch: 6, tloss: 2397.622314453125, vloss: 29798.8887: 100%|██████████| 469/469 [00:00<00:00, 879.23it/s]\n",
      "Epoch: 7, tloss: 101267.9921875, vloss: 32273.7695: 100%|██████████| 469/469 [00:00<00:00, 858.70it/s]\n",
      "Epoch: 8, tloss: 10350.314453125, vloss: 46365.8828: 100%|██████████| 469/469 [00:00<00:00, 922.31it/s]\n",
      "Epoch: 9, tloss: 18298.7578125, vloss: 34019.9023: 100%|██████████| 469/469 [00:00<00:00, 884.15it/s]\n",
      "Epoch: 10, tloss: 23067.48046875, vloss: 25502.2871: 100%|██████████| 469/469 [00:00<00:00, 861.00it/s]\n",
      "Epoch: 11, tloss: 7002.1044921875, vloss: 21716.1016: 100%|██████████| 469/469 [00:00<00:00, 892.69it/s]\n",
      "Epoch: 12, tloss: 75444.0234375, vloss: 78350.6250: 100%|██████████| 469/469 [00:00<00:00, 882.21it/s]\n",
      "Epoch: 13, tloss: 126540.21875, vloss: 21841.4688: 100%|██████████| 469/469 [00:00<00:00, 823.07it/s]\n",
      "Epoch: 14, tloss: 15731.123046875, vloss: 17566.0352: 100%|██████████| 469/469 [00:00<00:00, 785.92it/s]\n",
      "Epoch: 15, tloss: 10214.8427734375, vloss: 37468.8203: 100%|██████████| 469/469 [00:00<00:00, 793.42it/s]\n",
      "Epoch: 16, tloss: 18323.568359375, vloss: 13972.3389: 100%|██████████| 469/469 [00:00<00:00, 885.44it/s]\n",
      "Epoch: 17, tloss: 4161.57470703125, vloss: 31465.8047: 100%|██████████| 469/469 [00:00<00:00, 801.05it/s]\n",
      "Epoch: 18, tloss: 320371.71875, vloss: 103302.8828: 100%|██████████| 469/469 [00:00<00:00, 737.36it/s]\n",
      "Epoch: 19, tloss: 4786.015625, vloss: 44846.5000: 100%|██████████| 469/469 [00:00<00:00, 816.55it/s]\n",
      "Epoch: 20, tloss: 3658.512451171875, vloss: 17419.7793: 100%|██████████| 469/469 [00:00<00:00, 784.14it/s]\n",
      "Epoch: 21, tloss: 140668.15625, vloss: 22199.0645: 100%|██████████| 469/469 [00:00<00:00, 800.82it/s]\n",
      "Epoch: 22, tloss: 105203.234375, vloss: 9989.4287: 100%|██████████| 469/469 [00:00<00:00, 724.66it/s]\n",
      "Epoch: 23, tloss: 7169.208984375, vloss: 9019.3662: 100%|██████████| 469/469 [00:00<00:00, 732.22it/s]\n",
      "Epoch: 24, tloss: 33932.9921875, vloss: 14168.3613: 100%|██████████| 469/469 [00:00<00:00, 783.10it/s]\n",
      "Epoch: 25, tloss: 1117.5345458984375, vloss: 9663.2568: 100%|██████████| 469/469 [00:00<00:00, 847.42it/s]\n",
      "Epoch: 26, tloss: 3159.603271484375, vloss: 29519.7441: 100%|██████████| 469/469 [00:00<00:00, 735.06it/s]\n",
      "Epoch: 27, tloss: 5301.9873046875, vloss: 10789.1230: 100%|██████████| 469/469 [00:00<00:00, 840.98it/s]\n",
      "Epoch: 28, tloss: 11310.609375, vloss: 9873.7422: 100%|██████████| 469/469 [00:00<00:00, 798.53it/s]\n",
      "Epoch: 29, tloss: 9594.802734375, vloss: 13908.3984: 100%|██████████| 469/469 [00:00<00:00, 755.09it/s]\n",
      "Epoch: 30, tloss: 2622.018798828125, vloss: 9314.2490: 100%|██████████| 469/469 [00:00<00:00, 757.13it/s]\n",
      "Epoch: 31, tloss: 3365.49462890625, vloss: 12794.9580: 100%|██████████| 469/469 [00:00<00:00, 741.87it/s]\n",
      "Epoch: 32, tloss: 11830.4716796875, vloss: 12138.6826: 100%|██████████| 469/469 [00:00<00:00, 830.30it/s]\n",
      "Epoch: 33, tloss: 10316.76953125, vloss: 8647.4502: 100%|██████████| 469/469 [00:00<00:00, 860.78it/s]\n",
      "Epoch: 34, tloss: 18078.919921875, vloss: 7576.1836: 100%|██████████| 469/469 [00:00<00:00, 822.11it/s]\n",
      "Epoch: 35, tloss: 12827.373046875, vloss: 7313.3589: 100%|██████████| 469/469 [00:00<00:00, 927.41it/s]\n",
      "Epoch: 36, tloss: 4583.333984375, vloss: 8931.6807: 100%|██████████| 469/469 [00:00<00:00, 881.70it/s]\n",
      "Epoch: 37, tloss: 12989.146484375, vloss: 10573.0518: 100%|██████████| 469/469 [00:00<00:00, 793.28it/s]\n",
      "Epoch: 38, tloss: 6172.82958984375, vloss: 13261.9209: 100%|██████████| 469/469 [00:00<00:00, 755.07it/s]\n",
      "Epoch: 39, tloss: 10714.0625, vloss: 9628.9072: 100%|██████████| 469/469 [00:00<00:00, 731.42it/s]\n",
      "Epoch: 40, tloss: 4291.474609375, vloss: 6369.0771: 100%|██████████| 469/469 [00:00<00:00, 851.22it/s]\n",
      "Epoch: 41, tloss: 14950.169921875, vloss: 7897.5869: 100%|██████████| 469/469 [00:00<00:00, 927.52it/s]\n",
      "Epoch: 42, tloss: 975.5866088867188, vloss: 6270.2822: 100%|██████████| 469/469 [00:00<00:00, 894.44it/s]\n",
      "Epoch: 43, tloss: 935.1552124023438, vloss: 4898.2524: 100%|██████████| 469/469 [00:00<00:00, 706.64it/s]\n",
      "Epoch: 44, tloss: 4915.0751953125, vloss: 4058.4167: 100%|██████████| 469/469 [00:00<00:00, 714.39it/s]\n",
      "Epoch: 45, tloss: 4189.5751953125, vloss: 10619.1240: 100%|██████████| 469/469 [00:00<00:00, 723.26it/s]\n",
      "Epoch: 46, tloss: 3543.48486328125, vloss: 40053.7188: 100%|██████████| 469/469 [00:00<00:00, 740.99it/s]\n",
      "Epoch: 47, tloss: 2106.0693359375, vloss: 7620.7070: 100%|██████████| 469/469 [00:00<00:00, 740.71it/s]\n",
      "Epoch: 48, tloss: 2593.961181640625, vloss: 8117.8228: 100%|██████████| 469/469 [00:00<00:00, 803.01it/s]\n",
      "Epoch: 49, tloss: 3800.93310546875, vloss: 6396.9517: 100%|██████████| 469/469 [00:00<00:00, 899.02it/s]\n",
      "Epoch: 50, tloss: 4746.3720703125, vloss: 7183.2798: 100%|██████████| 469/469 [00:00<00:00, 773.09it/s]\n",
      "Epoch: 51, tloss: 2677.017578125, vloss: 5641.7983: 100%|██████████| 469/469 [00:00<00:00, 822.95it/s]\n",
      "Epoch: 52, tloss: 685.0241088867188, vloss: 3939.9702: 100%|██████████| 469/469 [00:00<00:00, 818.95it/s]\n",
      "Epoch: 53, tloss: 4698.9150390625, vloss: 6905.9756: 100%|██████████| 469/469 [00:00<00:00, 787.19it/s]\n",
      "Epoch: 54, tloss: 6931.6640625, vloss: 8041.3564: 100%|██████████| 469/469 [00:00<00:00, 738.84it/s]\n",
      "Epoch: 55, tloss: 3709.656982421875, vloss: 10113.4492: 100%|██████████| 469/469 [00:00<00:00, 761.45it/s]\n",
      "Epoch: 56, tloss: 1283.8494873046875, vloss: 5203.7896: 100%|██████████| 469/469 [00:00<00:00, 924.37it/s]\n",
      "Epoch: 57, tloss: 1517.56591796875, vloss: 7959.2598: 100%|██████████| 469/469 [00:00<00:00, 819.47it/s]\n",
      "Epoch: 58, tloss: 791.1234741210938, vloss: 26867.3086: 100%|██████████| 469/469 [00:00<00:00, 844.01it/s]\n",
      "Epoch: 59, tloss: 4786.35693359375, vloss: 5774.0005: 100%|██████████| 469/469 [00:00<00:00, 745.32it/s]\n",
      "Epoch: 60, tloss: 5758.32421875, vloss: 3657.7256: 100%|██████████| 469/469 [00:00<00:00, 818.43it/s]\n",
      "Epoch: 61, tloss: 14166.27734375, vloss: 15176.3467: 100%|██████████| 469/469 [00:00<00:00, 886.35it/s]\n",
      "Epoch: 62, tloss: 1861.0726318359375, vloss: 5475.2461: 100%|██████████| 469/469 [00:00<00:00, 823.11it/s]\n",
      "Epoch: 63, tloss: 4289.70166015625, vloss: 6899.9541: 100%|██████████| 469/469 [00:00<00:00, 835.85it/s]\n",
      "Epoch: 64, tloss: 5763.5869140625, vloss: 6533.5840: 100%|██████████| 469/469 [00:00<00:00, 843.02it/s]\n",
      "Epoch: 65, tloss: 1287.86865234375, vloss: 2935.6362: 100%|██████████| 469/469 [00:00<00:00, 808.43it/s]\n",
      "Epoch: 66, tloss: 1568.079345703125, vloss: 8333.8809: 100%|██████████| 469/469 [00:00<00:00, 869.59it/s]\n",
      "Epoch: 67, tloss: 1884.4310302734375, vloss: 5477.3950: 100%|██████████| 469/469 [00:00<00:00, 845.35it/s]\n",
      "Epoch: 68, tloss: 11279.90234375, vloss: 9576.9922: 100%|██████████| 469/469 [00:00<00:00, 783.30it/s]\n",
      "Epoch: 69, tloss: 983.5287475585938, vloss: 5251.3667: 100%|██████████| 469/469 [00:00<00:00, 956.14it/s]\n",
      "Epoch: 70, tloss: 10942.4130859375, vloss: 10022.5244: 100%|██████████| 469/469 [00:00<00:00, 765.16it/s]\n",
      "Epoch: 71, tloss: 1110.088623046875, vloss: 4183.0132: 100%|██████████| 469/469 [00:00<00:00, 838.92it/s]\n",
      "Epoch: 72, tloss: 44534.1875, vloss: 4700.2886: 100%|██████████| 469/469 [00:00<00:00, 774.05it/s]\n",
      "Epoch: 73, tloss: 21435.3515625, vloss: 5768.5137: 100%|██████████| 469/469 [00:00<00:00, 831.47it/s]\n",
      "Epoch: 74, tloss: 19719.794921875, vloss: 13482.4863: 100%|██████████| 469/469 [00:00<00:00, 917.73it/s]\n",
      "Epoch: 75, tloss: 11097.4990234375, vloss: 5261.7021: 100%|██████████| 469/469 [00:00<00:00, 775.04it/s]\n",
      "Epoch: 76, tloss: 4107.755859375, vloss: 4074.5715: 100%|██████████| 469/469 [00:00<00:00, 863.40it/s]\n",
      "Epoch: 77, tloss: 24763.162109375, vloss: 14499.7080: 100%|██████████| 469/469 [00:00<00:00, 967.39it/s]\n",
      "Epoch: 78, tloss: 974.2252807617188, vloss: 7471.8301: 100%|██████████| 469/469 [00:00<00:00, 866.49it/s]\n",
      "Epoch: 79, tloss: 23832.5625, vloss: 3078.3640: 100%|██████████| 469/469 [00:00<00:00, 812.55it/s]\n",
      "Epoch: 80, tloss: 1181.18798828125, vloss: 2449.7378: 100%|██████████| 469/469 [00:00<00:00, 766.45it/s]\n",
      "Epoch: 81, tloss: 7712.95458984375, vloss: 4763.3174: 100%|██████████| 469/469 [00:00<00:00, 789.90it/s]\n",
      "Epoch: 82, tloss: 48104.375, vloss: 23554.0801: 100%|██████████| 469/469 [00:00<00:00, 800.31it/s]\n",
      "Epoch: 83, tloss: 12656.099609375, vloss: 15099.6367: 100%|██████████| 469/469 [00:00<00:00, 842.48it/s]\n",
      "Epoch: 84, tloss: 13577.091796875, vloss: 12095.4316: 100%|██████████| 469/469 [00:00<00:00, 800.52it/s]\n",
      "Epoch: 85, tloss: 10823.1552734375, vloss: 4221.4873: 100%|██████████| 469/469 [00:00<00:00, 785.95it/s]\n",
      "Epoch: 86, tloss: 991.9689331054688, vloss: 2631.3679: 100%|██████████| 469/469 [00:00<00:00, 881.72it/s]\n",
      "Epoch: 87, tloss: 693.790771484375, vloss: 5189.3765: 100%|██████████| 469/469 [00:00<00:00, 868.93it/s]\n",
      "Epoch: 88, tloss: 3177.912109375, vloss: 3703.3518: 100%|██████████| 469/469 [00:00<00:00, 908.80it/s]\n",
      "Epoch: 89, tloss: 4114.138671875, vloss: 3356.7063: 100%|██████████| 469/469 [00:00<00:00, 854.43it/s]\n",
      "Epoch: 90, tloss: 3296.940185546875, vloss: 5819.1226: 100%|██████████| 469/469 [00:00<00:00, 881.20it/s]\n",
      "Epoch: 91, tloss: 4391.24755859375, vloss: 4357.1924: 100%|██████████| 469/469 [00:00<00:00, 861.33it/s]\n",
      "Epoch: 92, tloss: 15195.298828125, vloss: 8400.1621: 100%|██████████| 469/469 [00:00<00:00, 828.74it/s]\n",
      "Epoch: 93, tloss: 2349.45947265625, vloss: 5045.8901: 100%|██████████| 469/469 [00:00<00:00, 876.99it/s]\n",
      "Epoch: 94, tloss: 8538.9140625, vloss: 3768.0427: 100%|██████████| 469/469 [00:00<00:00, 775.81it/s]\n",
      "Epoch: 95, tloss: 485.5877685546875, vloss: 2850.3574: 100%|██████████| 469/469 [00:00<00:00, 883.20it/s]\n",
      "Epoch: 96, tloss: 8765.8203125, vloss: 6340.9014: 100%|██████████| 469/469 [00:00<00:00, 902.98it/s]\n",
      "Epoch: 97, tloss: 5450.376953125, vloss: 7577.2446: 100%|██████████| 469/469 [00:00<00:00, 845.54it/s]\n",
      "Epoch: 98, tloss: 29273.7734375, vloss: 4416.2510: 100%|██████████| 469/469 [00:00<00:00, 874.06it/s]\n",
      "Epoch: 99, tloss: 1728.1673583984375, vloss: 3453.7507: 100%|██████████| 469/469 [00:00<00:00, 738.60it/s]\n",
      "Epoch: 100, tloss: 5887.32568359375, vloss: 16281.0332: 100%|██████████| 469/469 [00:00<00:00, 885.35it/s]\n",
      "Epoch: 101, tloss: 926.501708984375, vloss: 2179.8071: 100%|██████████| 469/469 [00:00<00:00, 754.27it/s]\n",
      "Epoch: 102, tloss: 3255.87158203125, vloss: 1769.3475: 100%|██████████| 469/469 [00:00<00:00, 897.27it/s]\n",
      "Epoch: 103, tloss: 3296.261474609375, vloss: 6745.2847: 100%|██████████| 469/469 [00:00<00:00, 845.11it/s]\n",
      "Epoch: 104, tloss: 18214.08203125, vloss: 26609.8164: 100%|██████████| 469/469 [00:00<00:00, 775.55it/s]\n",
      "Epoch: 105, tloss: 594.8399658203125, vloss: 2198.8743: 100%|██████████| 469/469 [00:00<00:00, 775.08it/s]\n",
      "Epoch: 106, tloss: 1232.783935546875, vloss: 4906.0444: 100%|██████████| 469/469 [00:00<00:00, 784.70it/s]\n",
      "Epoch: 107, tloss: 9459.3876953125, vloss: 21728.7891: 100%|██████████| 469/469 [00:00<00:00, 898.56it/s]\n",
      "Epoch: 108, tloss: 33085.5390625, vloss: 7132.3848: 100%|██████████| 469/469 [00:00<00:00, 850.90it/s]\n",
      "Epoch: 109, tloss: 1198.518798828125, vloss: 2787.7588: 100%|██████████| 469/469 [00:00<00:00, 915.10it/s]\n",
      "Epoch: 110, tloss: 1536.606689453125, vloss: 3697.2600: 100%|██████████| 469/469 [00:00<00:00, 908.63it/s]\n",
      "Epoch: 111, tloss: 2790.0703125, vloss: 2719.8867: 100%|██████████| 469/469 [00:00<00:00, 928.08it/s]\n",
      "Epoch: 112, tloss: 698.6856689453125, vloss: 2785.9067: 100%|██████████| 469/469 [00:00<00:00, 952.30it/s]\n",
      "Epoch: 113, tloss: 1556.0419921875, vloss: 7380.9204: 100%|██████████| 469/469 [00:00<00:00, 930.32it/s]\n",
      "Epoch: 114, tloss: 4789.12841796875, vloss: 4495.6802: 100%|██████████| 469/469 [00:00<00:00, 950.42it/s]\n",
      "Epoch: 115, tloss: 7606.60546875, vloss: 4766.4668: 100%|██████████| 469/469 [00:00<00:00, 914.00it/s]\n",
      "Epoch: 116, tloss: 8637.234375, vloss: 6683.9917: 100%|██████████| 469/469 [00:00<00:00, 950.63it/s]\n",
      "Epoch: 117, tloss: 414.08636474609375, vloss: 1868.5448: 100%|██████████| 469/469 [00:00<00:00, 898.53it/s]\n",
      "Epoch: 118, tloss: 6239.0361328125, vloss: 6427.7783: 100%|██████████| 469/469 [00:00<00:00, 944.33it/s]\n",
      "Epoch: 119, tloss: 2964.80322265625, vloss: 12544.9873: 100%|██████████| 469/469 [00:00<00:00, 846.79it/s]\n",
      "Epoch: 120, tloss: 3330.153076171875, vloss: 13198.6006: 100%|██████████| 469/469 [00:00<00:00, 819.00it/s]\n",
      "Epoch: 121, tloss: 23806.1796875, vloss: 7756.2295: 100%|██████████| 469/469 [00:00<00:00, 954.67it/s]\n",
      "Epoch: 122, tloss: 3205.818359375, vloss: 2672.9802: 100%|██████████| 469/469 [00:00<00:00, 937.10it/s]\n",
      "Epoch: 123, tloss: 4528.44873046875, vloss: 3913.4680: 100%|██████████| 469/469 [00:00<00:00, 957.03it/s]\n",
      "Epoch: 124, tloss: 2876.041015625, vloss: 2982.5432: 100%|██████████| 469/469 [00:00<00:00, 936.15it/s]\n",
      "Epoch: 125, tloss: 1065.873046875, vloss: 2031.1348: 100%|██████████| 469/469 [00:00<00:00, 965.50it/s]\n",
      "Epoch: 126, tloss: 2853.34765625, vloss: 29588.3613: 100%|██████████| 469/469 [00:00<00:00, 934.45it/s]\n",
      "Epoch: 127, tloss: 7011.4326171875, vloss: 3551.7214: 100%|██████████| 469/469 [00:00<00:00, 953.30it/s]\n",
      "Epoch: 128, tloss: 13684.3701171875, vloss: 8949.1650: 100%|██████████| 469/469 [00:00<00:00, 965.11it/s]\n",
      "Epoch: 129, tloss: 2515.39013671875, vloss: 13412.6309: 100%|██████████| 469/469 [00:00<00:00, 952.62it/s]\n",
      "Epoch: 130, tloss: 7890.060546875, vloss: 3952.6592: 100%|██████████| 469/469 [00:00<00:00, 979.71it/s]\n",
      "Epoch: 131, tloss: 1021.0709838867188, vloss: 3546.4399: 100%|██████████| 469/469 [00:00<00:00, 939.54it/s]\n",
      "Epoch: 132, tloss: 5062.0126953125, vloss: 1620.2827: 100%|██████████| 469/469 [00:00<00:00, 826.14it/s]\n",
      "Epoch: 133, tloss: 3388.794677734375, vloss: 7189.2734: 100%|██████████| 469/469 [00:00<00:00, 831.76it/s]\n",
      "Epoch: 134, tloss: 1497.529052734375, vloss: 3073.2056: 100%|██████████| 469/469 [00:00<00:00, 806.61it/s]\n",
      "Epoch: 135, tloss: 11936.3046875, vloss: 6793.0864: 100%|██████████| 469/469 [00:00<00:00, 950.92it/s]\n",
      "Epoch: 136, tloss: 67260.3125, vloss: 12570.6875: 100%|██████████| 469/469 [00:00<00:00, 912.81it/s]\n",
      "Epoch: 137, tloss: 2886.784912109375, vloss: 5396.1689: 100%|██████████| 469/469 [00:00<00:00, 971.62it/s]\n",
      "Epoch: 138, tloss: 1341.626953125, vloss: 5009.9238: 100%|██████████| 469/469 [00:00<00:00, 904.90it/s]\n",
      "Epoch: 139, tloss: 990.2303466796875, vloss: 2871.1243: 100%|██████████| 469/469 [00:00<00:00, 955.87it/s]\n",
      "Epoch: 140, tloss: 353.01312255859375, vloss: 2503.7173: 100%|██████████| 469/469 [00:00<00:00, 937.04it/s]\n",
      "Epoch: 141, tloss: 8045.1279296875, vloss: 25268.2871: 100%|██████████| 469/469 [00:00<00:00, 906.87it/s]\n",
      "Epoch: 142, tloss: 515.2863159179688, vloss: 2672.7168: 100%|██████████| 469/469 [00:00<00:00, 952.90it/s]\n",
      "Epoch: 143, tloss: 2849.96875, vloss: 1574.6102: 100%|██████████| 469/469 [00:00<00:00, 958.28it/s]\n",
      "Epoch: 144, tloss: 10053.6640625, vloss: 4421.6445: 100%|██████████| 469/469 [00:00<00:00, 930.23it/s]\n",
      "Epoch: 145, tloss: 1275.68505859375, vloss: 4731.5273: 100%|██████████| 469/469 [00:00<00:00, 959.54it/s]\n",
      "Epoch: 146, tloss: 725.1723022460938, vloss: 3043.0347: 100%|██████████| 469/469 [00:00<00:00, 897.50it/s]\n",
      "Epoch: 147, tloss: 3088.255859375, vloss: 1980.6740: 100%|██████████| 469/469 [00:00<00:00, 964.62it/s]\n",
      "Epoch: 148, tloss: 1802.720458984375, vloss: 1431.3171: 100%|██████████| 469/469 [00:00<00:00, 831.68it/s]\n",
      "Epoch: 149, tloss: 3444.0234375, vloss: 10053.3457: 100%|██████████| 469/469 [00:00<00:00, 919.14it/s]\n",
      "Epoch: 150, tloss: 1099.4927978515625, vloss: 2144.0173: 100%|██████████| 469/469 [00:00<00:00, 892.17it/s]\n",
      "Epoch: 151, tloss: 1434.4794921875, vloss: 1629.9346: 100%|██████████| 469/469 [00:00<00:00, 945.22it/s]\n",
      "Epoch: 152, tloss: 18618.611328125, vloss: 2219.2083: 100%|██████████| 469/469 [00:00<00:00, 926.75it/s]\n",
      "Epoch: 153, tloss: 1263.593017578125, vloss: 6866.7021: 100%|██████████| 469/469 [00:00<00:00, 958.82it/s]\n",
      "Epoch: 154, tloss: 977.48095703125, vloss: 3980.4407: 100%|██████████| 469/469 [00:00<00:00, 953.07it/s]\n",
      "Epoch: 155, tloss: 702.2554931640625, vloss: 3796.7915: 100%|██████████| 469/469 [00:00<00:00, 948.91it/s]\n",
      "Epoch: 156, tloss: 652.7568359375, vloss: 1260.5908: 100%|██████████| 469/469 [00:00<00:00, 916.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 157, tloss: 2054.4560546875, vloss: 2979.4941: 100%|██████████| 469/469 [00:00<00:00, 881.40it/s]\n",
      "Epoch: 158, tloss: 17235.041015625, vloss: 4302.1318: 100%|██████████| 469/469 [00:00<00:00, 912.63it/s]\n",
      "Epoch: 159, tloss: 843.2201538085938, vloss: 1771.9208: 100%|██████████| 469/469 [00:00<00:00, 867.32it/s]\n",
      "Epoch: 160, tloss: 1258.90380859375, vloss: 3333.9963: 100%|██████████| 469/469 [00:00<00:00, 754.93it/s]\n",
      "Epoch: 161, tloss: 2825.046875, vloss: 1725.5721: 100%|██████████| 469/469 [00:00<00:00, 725.33it/s]\n",
      "Epoch: 162, tloss: 7628.6640625, vloss: 8862.7959: 100%|██████████| 469/469 [00:00<00:00, 752.39it/s]\n",
      "Epoch: 163, tloss: 3066.30078125, vloss: 7582.2622: 100%|██████████| 469/469 [00:00<00:00, 690.59it/s]\n",
      "Epoch: 164, tloss: 5633.6669921875, vloss: 8890.6211: 100%|██████████| 469/469 [00:00<00:00, 668.91it/s]\n",
      "Epoch: 165, tloss: 2585.5341796875, vloss: 7284.1846: 100%|██████████| 469/469 [00:00<00:00, 708.74it/s]\n",
      "Epoch: 166, tloss: 1864.259521484375, vloss: 2375.1606: 100%|██████████| 469/469 [00:00<00:00, 684.45it/s]\n",
      "Epoch: 167, tloss: 11649.4326171875, vloss: 2751.4482: 100%|██████████| 469/469 [00:00<00:00, 701.63it/s]\n",
      "Epoch: 168, tloss: 1099.924072265625, vloss: 1735.4443: 100%|██████████| 469/469 [00:00<00:00, 687.75it/s]\n",
      "Epoch: 169, tloss: 1046.1148681640625, vloss: 3383.3616: 100%|██████████| 469/469 [00:00<00:00, 706.94it/s]\n",
      "Epoch: 170, tloss: 2565.812744140625, vloss: 7242.7285: 100%|██████████| 469/469 [00:00<00:00, 739.22it/s]\n",
      "Epoch: 171, tloss: 28590.701171875, vloss: 5489.2129: 100%|██████████| 469/469 [00:00<00:00, 737.43it/s]\n",
      "Epoch: 172, tloss: 2244.217529296875, vloss: 13880.3516: 100%|██████████| 469/469 [00:00<00:00, 736.30it/s]\n",
      "Epoch: 173, tloss: 1457.767578125, vloss: 1391.7396: 100%|██████████| 469/469 [00:00<00:00, 733.53it/s]\n",
      "Epoch: 174, tloss: 2419.202880859375, vloss: 1719.0477: 100%|██████████| 469/469 [00:00<00:00, 729.75it/s]\n",
      "Epoch: 175, tloss: 627.82080078125, vloss: 1945.9011: 100%|██████████| 469/469 [00:00<00:00, 731.85it/s]\n",
      "Epoch: 176, tloss: 953.830078125, vloss: 1522.9227: 100%|██████████| 469/469 [00:00<00:00, 707.69it/s]\n",
      "Epoch: 177, tloss: 1444.831787109375, vloss: 1947.1799: 100%|██████████| 469/469 [00:00<00:00, 739.16it/s]\n",
      "Epoch: 178, tloss: 737.49609375, vloss: 1518.2603: 100%|██████████| 469/469 [00:00<00:00, 705.16it/s]\n",
      "Epoch: 179, tloss: 755.1393432617188, vloss: 1694.7695: 100%|██████████| 469/469 [00:00<00:00, 730.03it/s]\n",
      "Epoch: 180, tloss: 602.9268798828125, vloss: 2350.9800: 100%|██████████| 469/469 [00:00<00:00, 716.14it/s]\n",
      "Epoch: 181, tloss: 207.272216796875, vloss: 2619.7092: 100%|██████████| 469/469 [00:00<00:00, 711.99it/s]\n",
      "Epoch: 182, tloss: 12263.60546875, vloss: 29239.2637: 100%|██████████| 469/469 [00:00<00:00, 757.17it/s]\n",
      "Epoch: 183, tloss: 1224.837890625, vloss: 2282.4163: 100%|██████████| 469/469 [00:00<00:00, 796.82it/s]\n",
      "Epoch: 184, tloss: 1163.7255859375, vloss: 1129.7823: 100%|██████████| 469/469 [00:00<00:00, 735.35it/s]\n",
      "Epoch: 185, tloss: 14262.2060546875, vloss: 28631.2637: 100%|██████████| 469/469 [00:00<00:00, 739.45it/s]\n",
      "Epoch: 186, tloss: 543.6563720703125, vloss: 5477.8086: 100%|██████████| 469/469 [00:00<00:00, 708.72it/s]\n",
      "Epoch: 187, tloss: 1850.326416015625, vloss: 1630.5507: 100%|██████████| 469/469 [00:00<00:00, 696.54it/s]\n",
      "Epoch: 188, tloss: 6958.61083984375, vloss: 3014.4912: 100%|██████████| 469/469 [00:00<00:00, 717.38it/s]\n",
      "Epoch: 189, tloss: 2509.22412109375, vloss: 4120.8125: 100%|██████████| 469/469 [00:00<00:00, 704.36it/s]\n",
      "Epoch: 190, tloss: 1140.9437255859375, vloss: 1727.2976: 100%|██████████| 469/469 [00:00<00:00, 718.58it/s]\n",
      "Epoch: 191, tloss: 2191.16748046875, vloss: 3290.7314: 100%|██████████| 469/469 [00:00<00:00, 700.50it/s]\n",
      "Epoch: 192, tloss: 7466.181640625, vloss: 29752.2266: 100%|██████████| 469/469 [00:00<00:00, 732.84it/s]\n",
      "Epoch: 193, tloss: 3338.96337890625, vloss: 2373.1230: 100%|██████████| 469/469 [00:00<00:00, 701.06it/s]\n",
      "Epoch: 194, tloss: 804.3161010742188, vloss: 2189.2859: 100%|██████████| 469/469 [00:00<00:00, 694.45it/s]\n",
      "Epoch: 195, tloss: 8906.666015625, vloss: 1650.4490: 100%|██████████| 469/469 [00:00<00:00, 687.62it/s]\n",
      "Epoch: 196, tloss: 5146.41015625, vloss: 2370.6111: 100%|██████████| 469/469 [00:00<00:00, 683.06it/s]\n",
      "Epoch: 197, tloss: 1812.815185546875, vloss: 5844.0728: 100%|██████████| 469/469 [00:00<00:00, 712.10it/s]\n",
      "Epoch: 198, tloss: 2045.6907958984375, vloss: 2275.6780: 100%|██████████| 469/469 [00:00<00:00, 710.48it/s]\n",
      "Epoch: 199, tloss: 5120.294921875, vloss: 11770.6641: 100%|██████████| 469/469 [00:00<00:00, 730.94it/s]\n",
      "Epoch: 200, tloss: 2415.37939453125, vloss: 1262.6708: 100%|██████████| 469/469 [00:00<00:00, 726.08it/s]\n",
      "Epoch: 201, tloss: 4039.922607421875, vloss: 5504.3872: 100%|██████████| 469/469 [00:00<00:00, 720.43it/s]\n",
      "Epoch: 202, tloss: 570.5418701171875, vloss: 4242.0557: 100%|██████████| 469/469 [00:00<00:00, 731.13it/s]\n",
      "Epoch: 203, tloss: 7880.498046875, vloss: 1953.7356: 100%|██████████| 469/469 [00:00<00:00, 725.20it/s]\n",
      "Epoch: 204, tloss: 778.599609375, vloss: 5397.1592: 100%|██████████| 469/469 [00:00<00:00, 749.38it/s]\n",
      "Epoch: 205, tloss: 4518.3203125, vloss: 1249.5546: 100%|██████████| 469/469 [00:00<00:00, 779.76it/s]\n",
      "Epoch: 206, tloss: 1122.454345703125, vloss: 2497.4751: 100%|██████████| 469/469 [00:00<00:00, 729.44it/s]\n",
      "Epoch: 207, tloss: 1234.18017578125, vloss: 1204.6088: 100%|██████████| 469/469 [00:00<00:00, 726.32it/s]\n",
      "Epoch: 208, tloss: 3831.462646484375, vloss: 3591.4351: 100%|██████████| 469/469 [00:00<00:00, 722.23it/s]\n",
      "Epoch: 209, tloss: 3389.733154296875, vloss: 2089.3469: 100%|██████████| 469/469 [00:00<00:00, 714.26it/s]\n",
      "Epoch: 210, tloss: 2770.71435546875, vloss: 2695.5388: 100%|██████████| 469/469 [00:00<00:00, 735.95it/s]\n",
      "Epoch: 211, tloss: 1026.3359375, vloss: 1974.7815: 100%|██████████| 469/469 [00:00<00:00, 727.41it/s]\n",
      "Epoch: 212, tloss: 667.8438720703125, vloss: 2340.4758: 100%|██████████| 469/469 [00:00<00:00, 733.94it/s]\n",
      "Epoch: 213, tloss: 291.6073913574219, vloss: 1283.6445: 100%|██████████| 469/469 [00:00<00:00, 725.49it/s]\n",
      "Epoch: 214, tloss: 703.1215209960938, vloss: 3968.0078: 100%|██████████| 469/469 [00:00<00:00, 714.26it/s]\n",
      "Epoch: 215, tloss: 1995.2474365234375, vloss: 2015.3347: 100%|██████████| 469/469 [00:00<00:00, 711.39it/s]\n",
      "Epoch: 216, tloss: 1432.32666015625, vloss: 1890.2695: 100%|██████████| 469/469 [00:00<00:00, 718.50it/s]\n",
      "Epoch: 217, tloss: 2648.36572265625, vloss: 3826.4119: 100%|██████████| 469/469 [00:00<00:00, 701.16it/s]\n",
      "Epoch: 218, tloss: 6716.4072265625, vloss: 2829.9363: 100%|██████████| 469/469 [00:00<00:00, 714.83it/s]\n",
      "Epoch: 219, tloss: 9775.1611328125, vloss: 4898.5718: 100%|██████████| 469/469 [00:00<00:00, 719.21it/s]\n",
      "Epoch: 220, tloss: 2249.28662109375, vloss: 2142.7493: 100%|██████████| 469/469 [00:00<00:00, 702.33it/s]\n",
      "Epoch: 221, tloss: 1441.391845703125, vloss: 2025.7864: 100%|██████████| 469/469 [00:00<00:00, 723.51it/s]\n",
      "Epoch: 222, tloss: 5650.0546875, vloss: 4833.4360: 100%|██████████| 469/469 [00:00<00:00, 710.88it/s]\n",
      "Epoch: 223, tloss: 1143.6923828125, vloss: 3296.1206: 100%|██████████| 469/469 [00:00<00:00, 717.59it/s]\n",
      "Epoch: 224, tloss: 417.1092224121094, vloss: 1767.3319: 100%|██████████| 469/469 [00:00<00:00, 708.50it/s]\n",
      "Epoch: 225, tloss: 288.00341796875, vloss: 1344.4348: 100%|██████████| 469/469 [00:00<00:00, 724.35it/s]\n",
      "Epoch: 226, tloss: 2579.55322265625, vloss: 1491.3380: 100%|██████████| 469/469 [00:00<00:00, 712.58it/s]\n",
      "Epoch: 227, tloss: 273.24078369140625, vloss: 1895.9641: 100%|██████████| 469/469 [00:00<00:00, 744.16it/s]\n",
      "Epoch: 228, tloss: 2346.009521484375, vloss: 2268.8184: 100%|██████████| 469/469 [00:00<00:00, 766.23it/s]\n",
      "Epoch: 229, tloss: 286.3047790527344, vloss: 1389.9885: 100%|██████████| 469/469 [00:00<00:00, 779.98it/s]\n",
      "Epoch: 230, tloss: 2070.844482421875, vloss: 3287.8467: 100%|██████████| 469/469 [00:00<00:00, 738.52it/s]\n",
      "Epoch: 231, tloss: 1878.322998046875, vloss: 917.4674: 100%|██████████| 469/469 [00:00<00:00, 727.56it/s]\n",
      "Epoch: 232, tloss: 567.5023193359375, vloss: 1706.7915: 100%|██████████| 469/469 [00:00<00:00, 733.45it/s]\n",
      "Epoch: 233, tloss: 838.1329345703125, vloss: 2066.0640: 100%|██████████| 469/469 [00:00<00:00, 728.01it/s]\n",
      "Epoch: 234, tloss: 1922.640869140625, vloss: 2081.2935: 100%|██████████| 469/469 [00:00<00:00, 724.06it/s]\n",
      "Epoch: 235, tloss: 727.913330078125, vloss: 1227.0991: 100%|██████████| 469/469 [00:00<00:00, 749.83it/s]\n",
      "Epoch: 236, tloss: 3391.38037109375, vloss: 3454.3552: 100%|██████████| 469/469 [00:00<00:00, 718.22it/s]\n",
      "Epoch: 237, tloss: 2522.72607421875, vloss: 3415.4744: 100%|██████████| 469/469 [00:00<00:00, 727.67it/s]\n",
      "Epoch: 238, tloss: 98.21331787109375, vloss: 1007.5840: 100%|██████████| 469/469 [00:00<00:00, 726.59it/s]\n",
      "Epoch: 239, tloss: 547.320068359375, vloss: 1827.4857: 100%|██████████| 469/469 [00:00<00:00, 730.89it/s]\n",
      "Epoch: 240, tloss: 963.90283203125, vloss: 1649.2268: 100%|██████████| 469/469 [00:00<00:00, 729.80it/s]\n",
      "Epoch: 241, tloss: 4656.2890625, vloss: 3872.4048: 100%|██████████| 469/469 [00:00<00:00, 721.14it/s]\n",
      "Epoch: 242, tloss: 15449.021484375, vloss: 1486.9695: 100%|██████████| 469/469 [00:00<00:00, 730.93it/s]\n",
      "Epoch: 243, tloss: 6211.9326171875, vloss: 4023.3728: 100%|██████████| 469/469 [00:00<00:00, 719.41it/s]\n",
      "Epoch: 244, tloss: 6862.9951171875, vloss: 3824.3760: 100%|██████████| 469/469 [00:00<00:00, 903.52it/s]\n",
      "Epoch: 245, tloss: 966.7304077148438, vloss: 1048.7385: 100%|██████████| 469/469 [00:00<00:00, 840.83it/s]\n",
      "Epoch: 246, tloss: 2384.7822265625, vloss: 2751.3516: 100%|██████████| 469/469 [00:00<00:00, 880.66it/s]\n",
      "Epoch: 247, tloss: 342.7461853027344, vloss: 1474.6855: 100%|██████████| 469/469 [00:00<00:00, 895.68it/s]\n",
      "Epoch: 248, tloss: 1594.014404296875, vloss: 987.0616: 100%|██████████| 469/469 [00:00<00:00, 920.30it/s]\n",
      "Epoch: 249, tloss: 606.8966674804688, vloss: 1242.7877: 100%|██████████| 469/469 [00:00<00:00, 914.68it/s]\n",
      "Epoch: 250, tloss: 488.76019287109375, vloss: 3529.1311: 100%|██████████| 469/469 [00:00<00:00, 949.82it/s]\n",
      "Epoch: 251, tloss: 1237.9952392578125, vloss: 1339.7572: 100%|██████████| 469/469 [00:00<00:00, 845.09it/s]\n",
      "Epoch: 252, tloss: 1051.26025390625, vloss: 907.0164: 100%|██████████| 469/469 [00:00<00:00, 831.76it/s]\n",
      "Epoch: 253, tloss: 444.517578125, vloss: 5883.1270: 100%|██████████| 469/469 [00:00<00:00, 815.54it/s]\n",
      "Epoch: 254, tloss: 591.7318115234375, vloss: 1635.0891: 100%|██████████| 469/469 [00:00<00:00, 837.39it/s]\n",
      "Epoch: 255, tloss: 3975.078125, vloss: 3024.0156: 100%|██████████| 469/469 [00:00<00:00, 806.78it/s]\n",
      "Epoch: 256, tloss: 4081.113037109375, vloss: 20135.0664: 100%|██████████| 469/469 [00:00<00:00, 822.90it/s]\n",
      "Epoch: 257, tloss: 3867.118896484375, vloss: 1751.5260: 100%|██████████| 469/469 [00:00<00:00, 838.77it/s]\n",
      "Epoch: 258, tloss: 458.3174743652344, vloss: 1274.8694: 100%|██████████| 469/469 [00:00<00:00, 881.66it/s]\n",
      "Epoch: 259, tloss: 753.3890380859375, vloss: 3468.7271: 100%|██████████| 469/469 [00:00<00:00, 939.75it/s]\n",
      "Epoch: 260, tloss: 487.73260498046875, vloss: 1596.8672: 100%|██████████| 469/469 [00:00<00:00, 895.95it/s]\n",
      "Epoch: 261, tloss: 862.9308471679688, vloss: 3153.9128: 100%|██████████| 469/469 [00:00<00:00, 944.05it/s]\n",
      "Epoch: 262, tloss: 795.4198608398438, vloss: 1459.2729: 100%|██████████| 469/469 [00:00<00:00, 937.16it/s]\n",
      "Epoch: 263, tloss: 2936.680419921875, vloss: 1743.2404: 100%|██████████| 469/469 [00:00<00:00, 944.73it/s]\n",
      "Epoch: 264, tloss: 6167.982421875, vloss: 3965.2415: 100%|██████████| 469/469 [00:00<00:00, 883.52it/s]\n",
      "Epoch: 265, tloss: 6476.74755859375, vloss: 3733.9614: 100%|██████████| 469/469 [00:00<00:00, 951.13it/s]\n",
      "Epoch: 266, tloss: 675.1640625, vloss: 1745.3851: 100%|██████████| 469/469 [00:00<00:00, 953.84it/s]\n",
      "Epoch: 267, tloss: 2169.052001953125, vloss: 2035.3208: 100%|██████████| 469/469 [00:00<00:00, 961.78it/s]\n",
      "Epoch: 268, tloss: 2236.45849609375, vloss: 3965.1855: 100%|██████████| 469/469 [00:00<00:00, 936.54it/s]\n",
      "Epoch: 269, tloss: 224.8474578857422, vloss: 1077.6729: 100%|██████████| 469/469 [00:00<00:00, 926.40it/s]\n",
      "Epoch: 270, tloss: 2927.944091796875, vloss: 3284.4912: 100%|██████████| 469/469 [00:00<00:00, 949.43it/s]\n",
      "Epoch: 271, tloss: 1208.1962890625, vloss: 1011.1136: 100%|██████████| 469/469 [00:00<00:00, 906.71it/s]\n",
      "Epoch: 272, tloss: 9268.962890625, vloss: 7450.9678: 100%|██████████| 469/469 [00:00<00:00, 953.10it/s]\n",
      "Epoch: 273, tloss: 607.952392578125, vloss: 1550.4653: 100%|██████████| 469/469 [00:00<00:00, 907.82it/s]\n",
      "Epoch: 274, tloss: 1559.801025390625, vloss: 1261.6896: 100%|██████████| 469/469 [00:00<00:00, 949.17it/s]\n",
      "Epoch: 275, tloss: 448.26165771484375, vloss: 1126.7296: 100%|██████████| 469/469 [00:00<00:00, 937.58it/s]\n",
      "Epoch: 276, tloss: 10527.0498046875, vloss: 5622.8940: 100%|██████████| 469/469 [00:00<00:00, 950.38it/s]\n",
      "Epoch: 277, tloss: 294.778076171875, vloss: 3777.2114: 100%|██████████| 469/469 [00:00<00:00, 862.24it/s]\n",
      "Epoch: 278, tloss: 360.5708923339844, vloss: 1212.6378: 100%|██████████| 469/469 [00:00<00:00, 906.84it/s]\n",
      "Epoch: 279, tloss: 167.69192504882812, vloss: 1415.0702: 100%|██████████| 469/469 [00:00<00:00, 811.15it/s]\n",
      "Epoch: 280, tloss: 9405.3984375, vloss: 2291.5518: 100%|██████████| 469/469 [00:00<00:00, 835.02it/s]\n",
      "Epoch: 281, tloss: 1262.343505859375, vloss: 823.6301: 100%|██████████| 469/469 [00:00<00:00, 830.46it/s]\n",
      "Epoch: 282, tloss: 19128.01953125, vloss: 46560.0117: 100%|██████████| 469/469 [00:00<00:00, 871.20it/s]\n",
      "Epoch: 283, tloss: 1965.69921875, vloss: 2320.0388: 100%|██████████| 469/469 [00:00<00:00, 927.57it/s]\n",
      "Epoch: 284, tloss: 6987.70849609375, vloss: 1055.6135: 100%|██████████| 469/469 [00:00<00:00, 926.25it/s]\n",
      "Epoch: 285, tloss: 1118.256103515625, vloss: 2631.4768: 100%|██████████| 469/469 [00:00<00:00, 938.17it/s]\n",
      "Epoch: 286, tloss: 3014.56396484375, vloss: 3010.8401: 100%|██████████| 469/469 [00:00<00:00, 951.00it/s]\n",
      "Epoch: 287, tloss: 717.048095703125, vloss: 1093.7656: 100%|██████████| 469/469 [00:00<00:00, 956.57it/s]\n",
      "Epoch: 288, tloss: 1714.4447021484375, vloss: 2128.9387: 100%|██████████| 469/469 [00:00<00:00, 957.56it/s]\n",
      "Epoch: 289, tloss: 230.88140869140625, vloss: 1270.0961: 100%|██████████| 469/469 [00:00<00:00, 930.67it/s]\n",
      "Epoch: 290, tloss: 1185.6697998046875, vloss: 1104.5367: 100%|██████████| 469/469 [00:00<00:00, 881.45it/s]\n",
      "Epoch: 291, tloss: 630.382080078125, vloss: 1558.1669: 100%|██████████| 469/469 [00:00<00:00, 957.01it/s]\n",
      "Epoch: 292, tloss: 1067.2210693359375, vloss: 1319.9286: 100%|██████████| 469/469 [00:00<00:00, 946.18it/s]\n",
      "Epoch: 293, tloss: 608.367919921875, vloss: 1526.5532: 100%|██████████| 469/469 [00:00<00:00, 948.86it/s]\n",
      "Epoch: 294, tloss: 5575.68896484375, vloss: 2129.7544: 100%|██████████| 469/469 [00:00<00:00, 941.83it/s]\n",
      "Epoch: 295, tloss: 2045.3450927734375, vloss: 10877.6162: 100%|██████████| 469/469 [00:00<00:00, 924.15it/s]\n",
      "Epoch: 296, tloss: 1052.62451171875, vloss: 1221.9020: 100%|██████████| 469/469 [00:00<00:00, 739.02it/s]\n",
      "Epoch: 297, tloss: 4848.2841796875, vloss: 1906.1969: 100%|██████████| 469/469 [00:00<00:00, 736.93it/s]\n",
      "Epoch: 298, tloss: 773.27880859375, vloss: 803.7237: 100%|██████████| 469/469 [00:00<00:00, 741.78it/s]\n",
      "Epoch: 299, tloss: 1105.935302734375, vloss: 1828.2074: 100%|██████████| 469/469 [00:00<00:00, 745.46it/s]\n",
      "Epoch: 300, tloss: 1154.7135009765625, vloss: 1219.7568: 100%|██████████| 469/469 [00:00<00:00, 737.24it/s]\n",
      "Epoch: 301, tloss: 40.759246826171875, vloss: 1614.3068: 100%|██████████| 469/469 [00:00<00:00, 732.94it/s]\n",
      "Epoch: 302, tloss: 660.5889892578125, vloss: 1198.1765: 100%|██████████| 469/469 [00:00<00:00, 693.53it/s]\n",
      "Epoch: 303, tloss: 2839.958740234375, vloss: 947.9612: 100%|██████████| 469/469 [00:00<00:00, 722.78it/s]\n",
      "Epoch: 304, tloss: 2012.33251953125, vloss: 4303.4741: 100%|██████████| 469/469 [00:00<00:00, 730.05it/s]\n",
      "Epoch: 305, tloss: 2206.6015625, vloss: 8031.6284: 100%|██████████| 469/469 [00:00<00:00, 787.97it/s]\n",
      "Epoch: 306, tloss: 839.6830444335938, vloss: 1924.2920: 100%|██████████| 469/469 [00:00<00:00, 776.70it/s]\n",
      "Epoch: 307, tloss: 428.7527770996094, vloss: 1247.5142: 100%|██████████| 469/469 [00:00<00:00, 797.01it/s]\n",
      "Epoch: 308, tloss: 856.0868530273438, vloss: 3456.1982: 100%|██████████| 469/469 [00:00<00:00, 736.25it/s]\n",
      "Epoch: 309, tloss: 719.6116943359375, vloss: 2033.5051: 100%|██████████| 469/469 [00:00<00:00, 697.17it/s]\n",
      "Epoch: 310, tloss: 3096.280029296875, vloss: 2944.7031: 100%|██████████| 469/469 [00:00<00:00, 698.16it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 311, tloss: 691.433837890625, vloss: 894.6638: 100%|██████████| 469/469 [00:00<00:00, 702.69it/s]\n",
      "Epoch: 312, tloss: 703.0885009765625, vloss: 936.3942: 100%|██████████| 469/469 [00:00<00:00, 706.42it/s]\n",
      "Epoch: 313, tloss: 1618.0970458984375, vloss: 2386.3770: 100%|██████████| 469/469 [00:00<00:00, 861.12it/s]\n",
      "Epoch: 314, tloss: 3728.2978515625, vloss: 3643.2615: 100%|██████████| 469/469 [00:00<00:00, 958.82it/s]\n",
      "Epoch: 315, tloss: 1896.397705078125, vloss: 1519.8297: 100%|██████████| 469/469 [00:00<00:00, 764.86it/s]\n",
      "Epoch: 316, tloss: 1069.211669921875, vloss: 3399.3799: 100%|██████████| 469/469 [00:00<00:00, 746.41it/s]\n",
      "Epoch: 317, tloss: 15160.18359375, vloss: 1144.9973: 100%|██████████| 469/469 [00:00<00:00, 728.87it/s]\n",
      "Epoch: 318, tloss: 718.1124267578125, vloss: 1767.7284: 100%|██████████| 469/469 [00:00<00:00, 737.17it/s]\n",
      "Epoch: 319, tloss: 1910.9775390625, vloss: 1154.1372: 100%|██████████| 469/469 [00:00<00:00, 724.01it/s]\n",
      "Epoch: 320, tloss: 42396.15625, vloss: 1590.9481: 100%|██████████| 469/469 [00:00<00:00, 712.56it/s]\n",
      "Epoch: 321, tloss: 855.8544921875, vloss: 1233.4746: 100%|██████████| 469/469 [00:00<00:00, 719.36it/s]\n",
      "Epoch: 322, tloss: 12547.544921875, vloss: 9223.3115: 100%|██████████| 469/469 [00:00<00:00, 743.31it/s]\n",
      "Epoch: 323, tloss: 1827.00439453125, vloss: 1087.8235: 100%|██████████| 469/469 [00:00<00:00, 740.25it/s]\n",
      "Epoch: 324, tloss: 3942.620849609375, vloss: 5729.9390: 100%|██████████| 469/469 [00:00<00:00, 711.26it/s]\n",
      "Epoch: 325, tloss: 1364.3724365234375, vloss: 1057.0620: 100%|██████████| 469/469 [00:00<00:00, 725.73it/s]\n",
      "Epoch: 326, tloss: 960.59033203125, vloss: 912.8412: 100%|██████████| 469/469 [00:00<00:00, 711.28it/s]\n",
      "Epoch: 327, tloss: 1524.8798828125, vloss: 1585.2198: 100%|██████████| 469/469 [00:00<00:00, 729.94it/s]\n",
      "Epoch: 328, tloss: 2427.48095703125, vloss: 1768.1129: 100%|██████████| 469/469 [00:00<00:00, 774.54it/s]\n",
      "Epoch: 329, tloss: 1827.3060302734375, vloss: 10302.7617: 100%|██████████| 469/469 [00:00<00:00, 781.06it/s]\n",
      "Epoch: 330, tloss: 3047.755859375, vloss: 913.0825: 100%|██████████| 469/469 [00:00<00:00, 805.17it/s]\n",
      "Epoch: 331, tloss: 1958.8197021484375, vloss: 7911.7212: 100%|██████████| 469/469 [00:00<00:00, 751.26it/s]\n",
      "Epoch: 332, tloss: 669.0057373046875, vloss: 763.9206: 100%|██████████| 469/469 [00:00<00:00, 701.34it/s]\n",
      "Epoch: 333, tloss: 1340.284423828125, vloss: 1094.4266: 100%|██████████| 469/469 [00:00<00:00, 721.51it/s]\n",
      "Epoch: 334, tloss: 338.825927734375, vloss: 1271.6416: 100%|██████████| 469/469 [00:00<00:00, 721.63it/s]\n",
      "Epoch: 335, tloss: 4763.8798828125, vloss: 1805.5167: 100%|██████████| 469/469 [00:00<00:00, 731.71it/s]\n",
      "Epoch: 336, tloss: 1004.98388671875, vloss: 5926.4902: 100%|██████████| 469/469 [00:00<00:00, 722.65it/s]\n",
      "Epoch: 337, tloss: 3417.55224609375, vloss: 1140.0837: 100%|██████████| 469/469 [00:00<00:00, 707.39it/s]\n",
      "Epoch: 338, tloss: 229.2361297607422, vloss: 2959.4722: 100%|██████████| 469/469 [00:00<00:00, 716.31it/s]\n",
      "Epoch: 339, tloss: 19223.40234375, vloss: 9474.2061: 100%|██████████| 469/469 [00:00<00:00, 911.68it/s]\n",
      "Epoch: 340, tloss: 1294.0872802734375, vloss: 1353.8585: 100%|██████████| 469/469 [00:00<00:00, 925.53it/s]\n",
      "Epoch: 341, tloss: 1829.213134765625, vloss: 1723.3888: 100%|██████████| 469/469 [00:00<00:00, 918.84it/s]\n",
      "Epoch: 342, tloss: 465.79296875, vloss: 1698.4916: 100%|██████████| 469/469 [00:00<00:00, 938.19it/s]\n",
      "Epoch: 343, tloss: 7116.90234375, vloss: 7459.1309: 100%|██████████| 469/469 [00:00<00:00, 910.46it/s]\n",
      "Epoch: 344, tloss: 480.3802185058594, vloss: 1205.0371: 100%|██████████| 469/469 [00:00<00:00, 967.11it/s]\n",
      "Epoch: 345, tloss: 1502.5242919921875, vloss: 1296.6299: 100%|██████████| 469/469 [00:00<00:00, 914.85it/s]\n",
      "Epoch: 346, tloss: 2366.74267578125, vloss: 4879.8271: 100%|██████████| 469/469 [00:00<00:00, 940.95it/s]\n",
      "Epoch: 347, tloss: 1265.495361328125, vloss: 1893.0564: 100%|██████████| 469/469 [00:00<00:00, 943.73it/s]\n",
      "Epoch: 348, tloss: 2228.8681640625, vloss: 3134.0896: 100%|██████████| 469/469 [00:00<00:00, 949.18it/s]\n",
      "Epoch: 349, tloss: 474.09857177734375, vloss: 933.5434: 100%|██████████| 469/469 [00:00<00:00, 918.93it/s]\n",
      "Epoch: 350, tloss: 2338.55712890625, vloss: 791.0610: 100%|██████████| 469/469 [00:00<00:00, 990.43it/s]\n",
      "Epoch: 351, tloss: 1985.09423828125, vloss: 5341.9927: 100%|██████████| 469/469 [00:00<00:00, 945.55it/s]\n",
      "Epoch: 352, tloss: 547.1219482421875, vloss: 3186.3328: 100%|██████████| 469/469 [00:00<00:00, 954.73it/s]\n",
      "Epoch: 353, tloss: 1795.680419921875, vloss: 1269.1108: 100%|██████████| 469/469 [00:00<00:00, 970.98it/s]\n",
      "Epoch: 354, tloss: 3450.88720703125, vloss: 1301.7450: 100%|██████████| 469/469 [00:00<00:00, 846.49it/s]\n",
      "Epoch: 355, tloss: 358.8614196777344, vloss: 1190.1320: 100%|██████████| 469/469 [00:00<00:00, 835.05it/s]\n",
      "Epoch: 356, tloss: 781.6268310546875, vloss: 1051.0870: 100%|██████████| 469/469 [00:00<00:00, 863.80it/s]\n",
      "Epoch: 357, tloss: 290.431640625, vloss: 792.1356: 100%|██████████| 469/469 [00:00<00:00, 906.47it/s]\n",
      "Epoch: 358, tloss: 828.8594970703125, vloss: 3112.2900: 100%|██████████| 469/469 [00:00<00:00, 942.64it/s]\n",
      "Epoch: 359, tloss: 618.834716796875, vloss: 1491.6158: 100%|██████████| 469/469 [00:00<00:00, 915.04it/s]\n",
      "Epoch: 360, tloss: 559.916259765625, vloss: 4348.3066: 100%|██████████| 469/469 [00:00<00:00, 955.18it/s]\n",
      "Epoch: 361, tloss: 499.14788818359375, vloss: 921.1005: 100%|██████████| 469/469 [00:00<00:00, 914.37it/s]\n",
      "Epoch: 362, tloss: 1884.944091796875, vloss: 1569.8965: 100%|██████████| 469/469 [00:00<00:00, 933.26it/s]\n",
      "Epoch: 363, tloss: 2076.269775390625, vloss: 8587.7510: 100%|██████████| 469/469 [00:00<00:00, 933.58it/s]\n",
      "Epoch: 364, tloss: 3261.81005859375, vloss: 2734.6907: 100%|██████████| 469/469 [00:00<00:00, 972.19it/s]\n",
      "Epoch: 365, tloss: 718.4427490234375, vloss: 1195.9730: 100%|██████████| 469/469 [00:00<00:00, 929.81it/s]\n",
      "Epoch: 366, tloss: 940.9381713867188, vloss: 2067.5552: 100%|██████████| 469/469 [00:00<00:00, 935.37it/s]\n",
      "Epoch: 367, tloss: 1722.744873046875, vloss: 1501.4841: 100%|██████████| 469/469 [00:00<00:00, 940.40it/s]\n",
      "Epoch: 368, tloss: 1574.5511474609375, vloss: 1513.5216: 100%|██████████| 469/469 [00:00<00:00, 971.46it/s]\n",
      "Epoch: 369, tloss: 561.9921875, vloss: 2036.1708: 100%|██████████| 469/469 [00:00<00:00, 906.74it/s]\n",
      "Epoch: 370, tloss: 2137.459716796875, vloss: 749.0550: 100%|██████████| 469/469 [00:00<00:00, 976.15it/s]\n",
      "Epoch: 371, tloss: 269.803466796875, vloss: 956.4688: 100%|██████████| 469/469 [00:00<00:00, 960.71it/s]\n",
      "Epoch: 372, tloss: 96.64424133300781, vloss: 1387.1383: 100%|██████████| 469/469 [00:00<00:00, 932.21it/s]\n",
      "Epoch: 373, tloss: 620.6827392578125, vloss: 8065.2236: 100%|██████████| 469/469 [00:00<00:00, 943.15it/s]\n",
      "Epoch: 374, tloss: 644.7529296875, vloss: 1702.3784: 100%|██████████| 469/469 [00:00<00:00, 902.11it/s]\n",
      "Epoch: 375, tloss: 678.9005126953125, vloss: 831.1475: 100%|██████████| 469/469 [00:00<00:00, 938.42it/s]\n",
      "Epoch: 376, tloss: 1314.70166015625, vloss: 1093.1124: 100%|██████████| 469/469 [00:00<00:00, 924.75it/s]\n",
      "Epoch: 377, tloss: 5820.1220703125, vloss: 2515.3047: 100%|██████████| 469/469 [00:00<00:00, 950.84it/s]\n",
      "Epoch: 378, tloss: 2543.816162109375, vloss: 2764.9958: 100%|██████████| 469/469 [00:00<00:00, 929.11it/s]\n",
      "Epoch: 379, tloss: 1170.1329345703125, vloss: 8217.9775: 100%|██████████| 469/469 [00:00<00:00, 957.50it/s]\n",
      "Epoch: 380, tloss: 1210.5888671875, vloss: 937.4146: 100%|██████████| 469/469 [00:00<00:00, 906.30it/s]\n",
      "Epoch: 381, tloss: 1178.650390625, vloss: 2046.7024: 100%|██████████| 469/469 [00:00<00:00, 960.38it/s]\n",
      "Epoch: 382, tloss: 1067.2244873046875, vloss: 1034.4398: 100%|██████████| 469/469 [00:00<00:00, 812.09it/s]\n",
      "Epoch: 383, tloss: 436.32830810546875, vloss: 772.0924: 100%|██████████| 469/469 [00:00<00:00, 840.15it/s]\n",
      "Epoch: 384, tloss: 758.5661010742188, vloss: 1086.9684: 100%|██████████| 469/469 [00:00<00:00, 775.29it/s]\n",
      "Epoch: 385, tloss: 9359.65625, vloss: 1159.1964: 100%|██████████| 469/469 [00:00<00:00, 853.25it/s]\n",
      "Epoch: 386, tloss: 2826.53076171875, vloss: 1135.7366: 100%|██████████| 469/469 [00:00<00:00, 951.08it/s]\n",
      "Epoch: 387, tloss: 3856.95703125, vloss: 2607.5581: 100%|██████████| 469/469 [00:00<00:00, 900.87it/s]\n",
      "Epoch: 388, tloss: 4712.96875, vloss: 3500.1167: 100%|██████████| 469/469 [00:00<00:00, 932.53it/s]\n",
      "Epoch: 389, tloss: 1544.1185302734375, vloss: 1579.4752: 100%|██████████| 469/469 [00:00<00:00, 952.19it/s]\n",
      "Epoch: 390, tloss: 376.9376220703125, vloss: 985.2193: 100%|██████████| 469/469 [00:00<00:00, 950.49it/s]\n",
      "Epoch: 391, tloss: 24908.8984375, vloss: 3755.3230: 100%|██████████| 469/469 [00:00<00:00, 953.07it/s]\n",
      "Epoch: 392, tloss: 618.6788330078125, vloss: 1062.5536: 100%|██████████| 469/469 [00:00<00:00, 868.19it/s]\n",
      "Epoch: 393, tloss: 604.2101440429688, vloss: 800.4126: 100%|██████████| 469/469 [00:00<00:00, 707.04it/s]\n",
      "Epoch: 394, tloss: 578.8988037109375, vloss: 3562.9907: 100%|██████████| 469/469 [00:00<00:00, 710.64it/s]\n",
      "Epoch: 395, tloss: 2641.854248046875, vloss: 1760.6931: 100%|██████████| 469/469 [00:00<00:00, 725.50it/s]\n",
      "Epoch: 396, tloss: 673.7625732421875, vloss: 655.3254: 100%|██████████| 469/469 [00:00<00:00, 722.05it/s]\n",
      "Epoch: 397, tloss: 3633.33740234375, vloss: 1821.6530: 100%|██████████| 469/469 [00:00<00:00, 908.03it/s]\n",
      "Epoch: 398, tloss: 873.53662109375, vloss: 1085.6024: 100%|██████████| 469/469 [00:00<00:00, 712.03it/s]\n",
      "Epoch: 399, tloss: 2285.04345703125, vloss: 1201.2804: 100%|██████████| 469/469 [00:00<00:00, 703.09it/s]\n",
      "Epoch: 400, tloss: 2338.9345703125, vloss: 6768.2080: 100%|██████████| 469/469 [00:00<00:00, 876.97it/s]\n",
      "Epoch: 401, tloss: 306.2326354980469, vloss: 2081.4805: 100%|██████████| 469/469 [00:00<00:00, 705.40it/s]\n",
      "Epoch: 402, tloss: 778.4066162109375, vloss: 751.9526: 100%|██████████| 469/469 [00:00<00:00, 722.33it/s]\n",
      "Epoch: 403, tloss: 308.3490905761719, vloss: 1294.7253: 100%|██████████| 469/469 [00:00<00:00, 772.93it/s]\n",
      "Epoch: 404, tloss: 1381.209228515625, vloss: 1596.3938: 100%|██████████| 469/469 [00:00<00:00, 711.03it/s]\n",
      "Epoch: 405, tloss: 345.7398681640625, vloss: 1214.5183: 100%|██████████| 469/469 [00:00<00:00, 861.34it/s]\n",
      "Epoch: 406, tloss: 349.99420166015625, vloss: 1901.7382: 100%|██████████| 469/469 [00:00<00:00, 731.94it/s]\n",
      "Epoch: 407, tloss: 3475.55029296875, vloss: 2237.1829: 100%|██████████| 469/469 [00:00<00:00, 828.93it/s]\n",
      "Epoch: 408, tloss: 1679.808349609375, vloss: 798.1876: 100%|██████████| 469/469 [00:00<00:00, 774.86it/s]\n",
      "Epoch: 409, tloss: 1421.8909912109375, vloss: 1133.6395: 100%|██████████| 469/469 [00:00<00:00, 803.40it/s]\n",
      "Epoch: 410, tloss: 3980.668701171875, vloss: 3081.7954: 100%|██████████| 469/469 [00:00<00:00, 853.91it/s]\n",
      "Epoch: 411, tloss: 1230.40185546875, vloss: 715.7872: 100%|██████████| 469/469 [00:00<00:00, 787.49it/s]\n",
      "Epoch: 412, tloss: 4014.62060546875, vloss: 1313.6056: 100%|██████████| 469/469 [00:00<00:00, 784.03it/s]\n",
      "Epoch: 413, tloss: 263.6608581542969, vloss: 854.6598: 100%|██████████| 469/469 [00:00<00:00, 724.86it/s]\n",
      "Epoch: 414, tloss: 3061.31884765625, vloss: 923.8958: 100%|██████████| 469/469 [00:00<00:00, 760.80it/s]\n",
      "Epoch: 415, tloss: 4189.38330078125, vloss: 4427.9336: 100%|██████████| 469/469 [00:00<00:00, 743.70it/s]\n",
      "Epoch: 416, tloss: 282.3822937011719, vloss: 1666.7118: 100%|██████████| 469/469 [00:00<00:00, 727.40it/s]\n",
      "Epoch: 417, tloss: 2042.7939453125, vloss: 5271.1567: 100%|██████████| 469/469 [00:00<00:00, 850.99it/s]\n",
      "Epoch: 418, tloss: 709.8177490234375, vloss: 934.3098: 100%|██████████| 469/469 [00:00<00:00, 713.18it/s]\n",
      "Epoch: 419, tloss: 2991.369873046875, vloss: 1571.5289: 100%|██████████| 469/469 [00:00<00:00, 738.10it/s]\n",
      "Epoch: 420, tloss: 8249.9267578125, vloss: 934.2260: 100%|██████████| 469/469 [00:00<00:00, 726.71it/s]\n",
      "Epoch: 421, tloss: 446.4926452636719, vloss: 939.0016: 100%|██████████| 469/469 [00:00<00:00, 925.10it/s]\n",
      "Epoch: 422, tloss: 271.0458984375, vloss: 1912.5367: 100%|██████████| 469/469 [00:00<00:00, 755.66it/s]\n",
      "Epoch: 423, tloss: 4202.47265625, vloss: 4934.2671: 100%|██████████| 469/469 [00:00<00:00, 684.30it/s]\n",
      "Epoch: 424, tloss: 288.32293701171875, vloss: 737.2654: 100%|██████████| 469/469 [00:00<00:00, 739.20it/s]\n",
      "Epoch: 425, tloss: 551.4271240234375, vloss: 1485.6680: 100%|██████████| 469/469 [00:00<00:00, 749.19it/s]\n",
      "Epoch: 426, tloss: 719.5553588867188, vloss: 1079.8768: 100%|██████████| 469/469 [00:00<00:00, 784.53it/s]\n",
      "Epoch: 427, tloss: 161.43594360351562, vloss: 4251.9849: 100%|██████████| 469/469 [00:00<00:00, 881.92it/s]\n",
      "Epoch: 428, tloss: 2233.203857421875, vloss: 1658.3402: 100%|██████████| 469/469 [00:00<00:00, 702.07it/s]\n",
      "Epoch: 429, tloss: 1482.872802734375, vloss: 1500.9897: 100%|██████████| 469/469 [00:00<00:00, 725.11it/s]\n",
      "Epoch: 430, tloss: 11868.1044921875, vloss: 6721.9326: 100%|██████████| 469/469 [00:00<00:00, 734.89it/s]\n",
      "Epoch: 431, tloss: 1813.48046875, vloss: 1544.4583: 100%|██████████| 469/469 [00:00<00:00, 730.37it/s]\n",
      "Epoch: 432, tloss: 762.8710327148438, vloss: 895.2151: 100%|██████████| 469/469 [00:00<00:00, 729.61it/s]\n",
      "Epoch: 433, tloss: 518.509521484375, vloss: 5198.3433: 100%|██████████| 469/469 [00:00<00:00, 822.72it/s]\n",
      "Epoch: 434, tloss: 166.64578247070312, vloss: 801.6322: 100%|██████████| 469/469 [00:00<00:00, 889.53it/s]\n",
      "Epoch: 435, tloss: 1475.368896484375, vloss: 898.3934: 100%|██████████| 469/469 [00:00<00:00, 740.41it/s]\n",
      "Epoch: 436, tloss: 529.29833984375, vloss: 1043.0527: 100%|██████████| 469/469 [00:00<00:00, 739.55it/s]\n",
      "Epoch: 437, tloss: 579.0023193359375, vloss: 1388.5852: 100%|██████████| 469/469 [00:00<00:00, 833.86it/s]\n",
      "Epoch: 438, tloss: 11111.857421875, vloss: 22564.9238: 100%|██████████| 469/469 [00:00<00:00, 774.24it/s]\n",
      "Epoch: 439, tloss: 394.2434997558594, vloss: 888.2428: 100%|██████████| 469/469 [00:00<00:00, 794.55it/s]\n",
      "Epoch: 440, tloss: 448.54315185546875, vloss: 1383.8969: 100%|██████████| 469/469 [00:00<00:00, 729.70it/s]\n",
      "Epoch: 441, tloss: 143.8047637939453, vloss: 4863.3535: 100%|██████████| 469/469 [00:00<00:00, 845.09it/s]\n",
      "Epoch: 442, tloss: 572.32861328125, vloss: 1245.8264: 100%|██████████| 469/469 [00:00<00:00, 942.38it/s]\n",
      "Epoch: 443, tloss: 1110.1951904296875, vloss: 1569.6912: 100%|██████████| 469/469 [00:00<00:00, 832.86it/s]\n",
      "Epoch: 444, tloss: 5059.39599609375, vloss: 7353.3320: 100%|██████████| 469/469 [00:00<00:00, 743.23it/s]\n",
      "Epoch: 445, tloss: 2164.45751953125, vloss: 997.7474: 100%|██████████| 469/469 [00:00<00:00, 883.86it/s]\n",
      "Epoch: 446, tloss: 252.7777557373047, vloss: 738.9636: 100%|██████████| 469/469 [00:00<00:00, 769.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 25.59932518005371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "df = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/shapes-train.csv\")\n",
    "\n",
    "\n",
    "df_dummies = pd.get_dummies(df['shape']).astype(int)\n",
    "df = pd.concat([df, df_dummies], axis=1)\n",
    "result = df['cost']\n",
    "x_columns = df.columns.drop(['shape', 'cost', 'id'])\n",
    "x = df[x_columns].values\n",
    "y = result.values  \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "x_train = torch.tensor(x_train, device=device, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, device=device, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, device=device, dtype=torch.float32)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "dataset_train = TensorDataset(x_train, y_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataset_test = TensorDataset(x_test, y_test)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x_train.shape[1], 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 25),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(25, 1)\n",
    ").to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "es = EarlyStopping()\n",
    "epoch = 0\n",
    "done = False\n",
    "while epoch < 1000 and not done:\n",
    "    epoch += 1\n",
    "    steps = list(enumerate(dataloader_train))\n",
    "    pbar = tqdm.tqdm(steps)\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    for i, (x_batch, y_batch) in pbar:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        y_batch_pred = model(x_batch).flatten()\n",
    "        loss = loss_fn(y_batch_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i == len(steps) - 1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model(x_test).flatten()\n",
    "                vloss = loss_fn(pred, y_test)\n",
    "            if es(model, vloss):\n",
    "                done = True\n",
    "            pbar.set_description(f\"Epoch: {epoch}, tloss: {loss.item()}, vloss: {vloss.item():.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(x_test)\n",
    "    score = torch.sqrt(torch.nn.functional.mse_loss(pred.flatten(), y_test))\n",
    "print(f\"Final score (RMSE): {score.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "def perturbation_rank(device, model, x, y, names, regression):\n",
    "    model.to(device)\n",
    "    model.eval() # set the model to evaluation mode\n",
    "\n",
    "    #x = torch.tensor(x).float().to(device)\n",
    "    #y = torch.tensor(y).float().to(device)\n",
    "    errors = []\n",
    "    for i in range(x.shape[1]):\n",
    "        hold = x[:, i].clone()\n",
    "        x[:, i] = torch.randperm(x.shape[0]).to(device)  # shuffling\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "\n",
    "        if regression:\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            error = loss_fn(y, pred).item()\n",
    "        else:\n",
    "            # pred should be probabilities; apply softmax if not done in model's forward method\n",
    "            if len(pred.shape) == 2 and pred.shape[1] > 1:\n",
    "                pred = F.softmax(pred, dim=1)\n",
    "                loss_fn = torch.nn.CrossEntropyLoss()\n",
    "                error = loss_fn(pred, y.long()).item()\n",
    "            else:\n",
    "                loss_fn = nn.MSELoss()\n",
    "                error = loss_fn(y, pred).item()\n",
    "            \n",
    "            \n",
    "        errors.append(error)\n",
    "        x[:, i] = hold\n",
    "        \n",
    "    max_error = max(errors)\n",
    "    importance = [e/max_error for e in errors]\n",
    "\n",
    "    data = {'name':names, 'error':errors, 'importance':importance}\n",
    "    result = pd.DataFrame(data, columns=['name', 'error', 'importance'])\n",
    "    result.sort_values(by=['importance'], ascending=[0], inplace=True)\n",
    "    result.reset_index(inplace=True, drop=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['height', 'width', 'depth', 'quality', 'box', 'cylinder', 'ellipsoid']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luozi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([2500, 1])) that is different to the input size (torch.Size([2500])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>error</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>height</td>\n",
       "      <td>3.359627e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depth</td>\n",
       "      <td>2.849031e+07</td>\n",
       "      <td>0.848020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>width</td>\n",
       "      <td>1.179454e+07</td>\n",
       "      <td>0.351067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quality</td>\n",
       "      <td>2.735138e+06</td>\n",
       "      <td>0.081412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ellipsoid</td>\n",
       "      <td>1.364313e+06</td>\n",
       "      <td>0.040609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>box</td>\n",
       "      <td>9.618084e+05</td>\n",
       "      <td>0.028628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cylinder</td>\n",
       "      <td>9.605467e+05</td>\n",
       "      <td>0.028591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name         error  importance\n",
       "0     height  3.359627e+07    1.000000\n",
       "1      depth  2.849031e+07    0.848020\n",
       "2      width  1.179454e+07    0.351067\n",
       "3    quality  2.735138e+06    0.081412\n",
       "4  ellipsoid  1.364313e+06    0.040609\n",
       "5        box  9.618084e+05    0.028628\n",
       "6   cylinder  9.605467e+05    0.028591"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "names = list(df.columns) \n",
    "names.remove('id')\n",
    "names.remove('shape')\n",
    "names.remove(\"cost\")  \n",
    "print(names)\n",
    "\n",
    "rank = perturbation_rank(device, model, x_test, y_test, names, True)\n",
    "display(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             cost     id\n",
      "0       16.262226  10001\n",
      "1      343.610382  10002\n",
      "2       16.262226  10003\n",
      "3     1008.516418  10004\n",
      "4      284.315887  10005\n",
      "...           ...    ...\n",
      "1995   825.185364  11996\n",
      "1996   291.880096  11997\n",
      "1997   269.080292  11998\n",
      "1998    16.262226  11999\n",
      "1999    16.262226  12000\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_submit = pd.read_csv(\"https://data.heatonresearch.com/data/t81-558/datasets/shapes-test.csv\")\n",
    "id_col = df_submit['id']\n",
    "df_dummies = pd.get_dummies(df_submit['shape']).astype(int)\n",
    "df_submit = pd.concat([df_submit, df_dummies], axis=1)\n",
    "x_columns_submit = df_submit.columns.drop(['shape', 'id'])\n",
    "x_submit = df_submit[x_columns_submit].values\n",
    "x_pred_submit = torch.tensor(x_submit, device=device, dtype=torch.float32)\n",
    "\n",
    "pred_submit = model(x_pred_submit)\n",
    "df_submit = pd.DataFrame(pred_submit.cpu().detach().numpy(), columns=['cost'])\n",
    "df_submit['id'] = id_col\n",
    "print(df_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Submitted Assignment 8 for luozihan:\n",
      "You have submitted this assignment 2 times. (this is fine)\n",
      "Note: The mean difference 2.6676492159999725 for column 'cost' is acceptable and is less than the maximum allowed value of '50.0' for this assignment.\n",
      "No warnings or errors (only notes), you will probably do well, but no guarantee. :-)\n"
     ]
    }
   ],
   "source": [
    "submit(source_file=file,data=[df_submit],key=key,no=8)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_solution_class8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
